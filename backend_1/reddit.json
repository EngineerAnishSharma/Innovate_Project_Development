{
    "subreddit": {
        "display_name": "Python",
        "title": "Python"
    },
    "posts": [
        {
            "id": "0",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iks79k/a_new_type_of_interpreter_has_been_added_to/"
            },
            "content": "<p>A new type of interpreter has been added to Python 3.14 with much better performance</p><p>Summary: This week I landed a new type of interpreter into Python 3.14. It improves performance by -3-30% (I actually removed outliers, otherwise it's 45%), and a geometric mean of 9-15% faster on pyperformance depending on platform and architecture.\u00a0**The main caveat however is that it only works with the newest compilers (Clang 19 and newer).**\u00a0We made this opt-in, so there's no backward compatibility concerns. Once the compilers start catching up a few years down the road, I expect this feature to become widespread.\n\nPython 3.14 documentation: [https://docs.python.org/3.14/whatsnew/3.14.html#whatsnew314-tail-call](https://docs.python.org/3.14/whatsnew/3.14.html#whatsnew314-tail-call)\n\nI have a lot of people to thank for their ideas and help: Mark Shannon, Donghee Na, Diego Russo, Garrett Gu, Haoran Xu, and Josh Haberman. Also my academic supervisors Stefan Marr and Manuel Rigger :).\n\n(Sorry can't cross-post here) Original post: [https://www.reddit.com/r/ProgrammingLanguages/comments/1ikqi0d/a\\_new\\_type\\_of\\_interpreter\\_has\\_been\\_added\\_to/](https://www.reddit.com/r/ProgrammingLanguages/comments/1ikqi0d/a_new_type_of_interpreter_has_been_added_to/)</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iks79k/a_new_type_of_interpreter_has_been_added_to/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iks79k/a_new_type_of_interpreter_has_been_added_to/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "1",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ii64gp/how_rust_is_quietly_taking_over_the_python/"
            },
            "content": "<p>How Rust is quietly taking over the Python ecosystem</p><p>Been noticing an interesting trend lately - Rust is becoming the secret sauce behind many of Python's most innovative tools. As someone who works with Python daily, it's fascinating to see how the ecosystem is evolving.\n\nHere's what's caught my attention:\n\n* **Ruff**: This linter is absurdly fast compared to traditional Python linters. Why? It's written in Rust. We're talking 10-100x speedups here.\n* **PyOxidizer**: A solid solution for creating standalone Python applications. Again, Rust. (unfortunately not maintained anymore)\n* **Polars**: This DataFrame library is giving Pandas a run for its money in terms of performance. Guess what? Rust under the hood.\n* **Maturin**: Making it dead simple to create Python extensions in Rust.\n\nMy team has written a blog post diving deeper into this trend, specifically looking at PyO3 (the framework that makes Python/Rust integration possible) and showing how to build your own high-performance Python extensions with Rust. If you wish, you can read it here: [https://www.blueshoe.io/blog/python-rust-pyo3/](https://www.blueshoe.io/blog/python-rust-pyo3/)\n\nThe really interesting part is that most Python developers don't even realize they're using Rust-powered tools. It's like Rust is becoming Python's performance co-pilot without much fanfare.\n\nWhat are your thoughts on this trend? Have you tried building any Python extensions with Rust?\n\n*Full disclosure: Our team at Blueshoe wrote the blog post, but I genuinely think this is an important trend worth discussing.*</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ii64gp/how_rust_is_quietly_taking_over_the_python/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ii64gp/how_rust_is_quietly_taking_over_the_python/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "2",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iwccvr/i_built_an_opensource_algo_trading_framework_for/"
            },
            "content": "<p>I Built an Open-Source Algo Trading Framework for Instant Backtests & Live Deployment</p><p>**Github** : [https://github.com/himanshu2406/Algo.Py](https://github.com/himanshu2406/Algo.Py)\n\n# What My Project Does\n\nSo I've been working on a framework made in Python that makes **live trading** incredibly easy, and even almost no-code !\n\nIt seamlessly integrates with **any preset backtesting strategy**, allowing you to take them **straight to live trading** with minimal effort.\n\n**Dashboard Overview :** [https://youtu.be/OmlaBnGcUi4?si=e1aizaIaYpRNMHFd](https://youtu.be/OmlaBnGcUi4?si=e1aizaIaYpRNMHFd)\n\n**One-Click Backtest Deployment Overview :** [https://youtu.be/T\\_otTHdLCCY?si=A7ujRzV6I5ESfgEQ](https://youtu.be/T_otTHdLCCY?si=A7ujRzV6I5ESfgEQ)\n\nIt's still in very **early beta**, but I\u2019ve packed in as many functional features as possible, including:\n\n# Key Features\n\n* **Intuitive Dashboard**\n* Easily **backtest, view results,  save and deploy** in a single click.\n   * **Auto-Detects Your Strategy** \u2013 If your function generates valid entry/exit signals, the framework will **automatically detect and integrate it**.\n   * **Scheduler for Automation** \u2013 Run your entire pipeline at custom **fixed intervals or specific times**\n* **Custom Data Layer (Finstore):**\n* Stores and streams data using a **Parquet-based data lake**, making it **much faster** than traditional databases.\n   * **Multi-Broker Support** \u2013 Execute across multiple brokers with **real-time debug logs** via Telegram.\n   * **End-to-End Pipelines** \u2013 Effortlessly fetch, store, and stream data for **crypto, equities, and more**.\n* **Multi-Asset Backtests** :\n   * Backtest a strategy across an entire market across hundreds of symbols and thousands of data points within seconds.\n   * One-Click backtests across entire markets : Crypto , U.S Equity , Indian Equity & adding more.\n\n# Advanced Market Visualization\n\n**Live Order Book Heatmap** \u2013 Real-time Binance order book visualization. Represents market orders with volume bubbles to identify iceberg orders easily. Also Visualizes resting orders on the orderbook.\n\n**Live Footprint Chart** \u2013 Captures trade flow via Binance WebSocket data. Makes order book trading extremely easy.\n\n# Smart OMS (Order Management System)\n\n* **Limit Order Chaser** \u2013 Reduces fees by executing market orders **while chasing the mark price**.\n* **AI-Powered OMS** \u2013 An autonomous AI agent can **execute, close, and manage trades**, plus run **complex local strategies**.\n\n# Risk Management System (RMS)\n\n* **Portfolio Aggregation** \u2013 Monitors all broker portfolios to **notify and manage over-exposed positions**.\n\n*And working on many other features & improvements!*\n\n# Target Audience\n\n* Anyone who wants to backtest or deploy their strategies but don't have a lot of technical know-how on how to build their own framework\n* Retail traders who have been manually implementing their strategies - can now easily automate them across entire markets.\n* Quant Traders who want to build a common robust community framework for algo trading.\n\n# Comparison\n\n* backtesting py :  seems to be outdated but only works on implementing strategy backtests but doesn't offer strategy deployment with ease.\n* tensorcharts , quantower, etc : charting platforms that provide advanced charting for L1, L2 Data for a hefty price. This can now be done for free locally.\n* PyAlgoTrade : Also deprecated but alternatives do not offer a framework to deploy strategies.\n\nThe repo still has tons of stale code and bugs but I would **love for some of you to test it out!**\n\nLet me know what you guys think !</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iwccvr/i_built_an_opensource_algo_trading_framework_for/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iwccvr/i_built_an_opensource_algo_trading_framework_for/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "3",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1isv37n/is_uv_package_manager_taking_over/"
            },
            "content": "<p>Is UV package manager taking over?</p><p>Hi!\nI am a devops engineer and notice developers talking about uv package manager.  I used it today for the first time and loved it. It seems like everyone is talking to agrees. Does anyone have and cons for us package manager?</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1isv37n/is_uv_package_manager_taking_over/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1isv37n/is_uv_package_manager_taking_over/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "4",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iuyt0y/new_to_coding_is_it_always_this_difficult/"
            },
            "content": "<p>New to coding. Is it always this difficult?</p><p>I\u2019m transitioning from bartending to data analysis at 37yo through an online course called CareerFoundry and I think I\u2019ve made a huge mistake. I do not feel prepared to enter the job market with my new skills. For example It has taken me 6 full hours today just trying to START a project in VSCode and I don\u2019t understand any of the troubleshooting I\u2019m doing. (I don\u2019t remember learning about virtual environments during the course) we did the whole course in Jupyter and now I find out vscode is the standard and it\u2019s an entirely different platform I can\u2019t figure out. I feel like every step forward is 100 steps back. \n\nCould anyone share their \u201caha!\u201d Moment with coding? I could really use the encouragement. Or have I made a huge mistake and this just isn\u2019t for me? Thanks for reading this far!! Any advice is appreciated. </p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iuyt0y/new_to_coding_is_it_always_this_difficult/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iuyt0y/new_to_coding_is_it_always_this_difficult/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "5",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1itzac1/what_the_hell_is_going_on_with_type_hinting_these/"
            },
            "content": "<p>What the hell is going on with type hinting these days</p><p>When I first learned python back in versions 3.6 and 3.7 I regarded type hinting as a purely styling feature.  It was well rooted in my mind that python code with or without type hinting will run the same and it is used only for readability -- basically just us developers being kind to each other.\n\nNowadays more and more packages are using type hinting for core functions. SQLAlchemy is using it to declare SQL column types (Mapped), FastAPI + Pydantic is using it for HTTP payloads and auto-documentation, and dataclasses uses it to construct (shockingly) data classes.\n\nDon't get me wrong, I'm supportive of type hinting\\\\annotations. I'm also well aware that all of these packages will execute just fine without it. But maybe it's fair to say that in modern python applications type hinting is a core feature and not just for styling and garnishing.\n\nEdit: I actually find type annotations very useful, I'm not against it. I wanted to discuss whether it's really \"optional\" due to its widespread integration in libraries. I like u/all4Nature point: I'm thinking on it from a software engineer prespective, data analysts will probably disagree that type hinting is as widespread as I thought.</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1itzac1/what_the_hell_is_going_on_with_type_hinting_these/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1itzac1/what_the_hell_is_going_on_with_type_hinting_these/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "6",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1itu5mn/happy_birthday_python/"
            },
            "content": "<p>Happy Birthday, Python! \ud83c\udf89\ud83d\udc0d</p><p>Guido van Rossum began working on Python language in the late 1980s as a successor to the ABC programming language. The first version, Python 0.9.0, was released on this day, February 20, 1991. </p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1itu5mn/happy_birthday_python/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1itu5mn/happy_birthday_python/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "7",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1if3axy/introducing_kreuzberg_a_simple_modern_library_for/"
            },
            "content": "<p>Introducing Kreuzberg: A Simple, Modern Library for PDF and Document Text Extraction in Python</p><p>Hey folks! I recently created Kreuzberg, a Python library that makes text extraction from PDFs and other documents simple and hassle-free. \n\nI built this while working on a RAG system and found that existing solutions either required expensive API calls were overly complex for my text extraction needs, or involved large docker images and complex deployments.  \n\nKey Features:\n\n- Modern Python with async support and type hints\n- Extract text from PDFs (both searchable and scanned), images, and office documents\n- Local processing - no API calls needed\n- Lightweight - no GPU requirements\n- Extensive error handling for easy debugging\n\n## Target Audience:\nThis library is perfect for developers working on RAG systems, document processing pipelines, or anyone needing reliable text extraction without the complexity of commercial APIs. It's designed to be simple to use while handling a wide range of document formats.\n\n```python\nfrom kreuzberg import extract_bytes, extract_file\n\n# Extract text from a PDF file\nasync def extract_pdf():\n    result = await extract_file(\"document.pdf\")\n    print(f\"Extracted text: {result.content}\")\n    print(f\"Output mime type: {result.mime_type}\")\n\n# Extract text from an image\nasync def extract_image():\n    result = await extract_file(\"scan.png\")\n    print(f\"Extracted text: {result.content}\")\n\n# Or extract from a byte string\n\n# Extract text from PDF bytes\nasync def process_uploaded_pdf(pdf_content: bytes):\n    result = await extract_bytes(pdf_content, mime_type=\"application/pdf\")\n    return result.content\n\n\n# Extract text from image bytes\nasync def process_uploaded_image(image_content: bytes):\n    result = await extract_bytes(image_content, mime_type=\"image/jpeg\")\n    return result.content\n```\n\n## Comparison:\nUnlike commercial solutions requiring API calls and usage limits, Kreuzberg runs entirely locally. \n\nCompared to other open-source alternatives, it offers a simpler API while still supporting a comprehensive range of formats, including:\n\n- PDFs (searchable and scanned)\n- Images (JPEG, PNG, TIFF, etc.)\n- Office documents (DOCX, ODT, RTF)\n- Plain text and markup formats\n\nCheck out the [GitHub repository](https://github.com/Goldziher/kreuzberg) for more details and examples. If you find this useful, a \u2b50 would be greatly appreciated!\n\nThe library is MIT-licensed and open to contributions. Let me know if you have any questions or feedback!</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1if3axy/introducing_kreuzberg_a_simple_modern_library_for/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1if3axy/introducing_kreuzberg_a_simple_modern_library_for/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "8",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iume26/appreciation_post_for_pycharm/"
            },
            "content": "<p>Appreciation post for PyCharm</p><p>I spent the entire day today working on some complex ETL. So many hours spent building, testing, fine-tuning. Once I got it working I was updating the built in sphinx documentation, running the \u2018make html\u2019 command several times in the terminal. Turns out I had at one point in this active terminal, done a \u2018git reset \u2014hard\u2019 command. While pressing up to cycle through commands, I accidentally ran git reset hard. All my work for the entire day was GONE. I have f\u2019d up at work before, but never this bad. I was mortified.\n\nI had a moment of panic, and then asked chatGPT if there was any way to recover. The git log options it gave did not work. I then asked if PyCharm had any solutions for this. THERE IS A LOCAL HISTORY FEATURE THAT SAVED ME. It saves your changes and I was able to recover it all. Thank you to JetBrains for this amazing product. Four years with this product and I\u2019m still learning about amazing features like this. </p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iume26/appreciation_post_for_pycharm/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iume26/appreciation_post_for_pycharm/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "9",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iurnjd/follow_the_yearly_pycon_if_you_want_to_get_better/"
            },
            "content": "<p>Follow the yearly PyCon if you want to get better at using Python</p><p>One very under-appreciated advice I'm often giving to people starting with Python (or wanting to dive much deeper) is to follow the annual Python Conference (PyCon) and watch a few talks. \n\nBy far not all of them are relevant for most people. Some thing go very deep in how the language works intrinsically, or marginal optimizations for machine-learning stacks, but by and large it's really one of the best ways to keep up with the language and the community.\n\n  \nJust search \"PyCon 20xx\" (e.g 2024) on Youtube and you'll find most/all of them there.\n\n  \nFor example, one talk I absolutely love from the PyCon 2018 (yes, 2018!) is a talk by Hillel Wayne on testing better: [https://www.youtube.com/watch?v=MYucYon2-lk](https://www.youtube.com/watch?v=MYucYon2-lk)\n\nSome things get old, deprecated, some things are just making you a better dev.</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iurnjd/follow_the_yearly_pycon_if_you_want_to_get_better/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iurnjd/follow_the_yearly_pycon_if_you_want_to_get_better/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "10",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ipxhsk/i_published_my_third_opensource_python_package_to/"
            },
            "content": "<p>I published my third open-source python package to pypi</p><p>Hey everyone,\n\nI published my 3rd pypi lib and it's open source. It's called\u00a0**stealthkit**\u00a0\\- requests on steroids. Good for those who want to send http requests to websites that might not allow it through programming - like amazon, yahoo finance, stock exchanges, etc.\n\n**What My Project Does**\n\n* **User-Agent Rotation**: Automatically rotates user agents from Chrome, Edge, and Safari across different OS platforms (Windows, MacOS, Linux).\n* **Random Referer Selection**: Simulates real browsing behavior by sending requests with randomized referers from search engines.\n* **Cookie Handling**: Fetches and stores cookies from specified URLs to maintain session persistence.\n* **Proxy Support**: Allows requests to be routed through a provided proxy.\n* **Retry Logic**: Retries failed requests up to three times before giving up.\n* **RESTful Requests**: Supports GET, POST, PUT, and DELETE methods with automatic proxy integration.\n\n**Why did I create it?**\n\nIn 2020, I created a yahoo finance lib and it required me to tweak python's requests module heavily - like session, cookies, headers, etc.\n\nIn 2022, I worked on my django project which required it to fetch amazon product data; again I needed requests workaround.\n\nThis year, I created second pypi - amzpy. And I soon understood that all of my projects evolve around web scraping and data processing. So I created a separate lib which can be used in multiple projects. And I am working on another stock exchange python api wrapper which uses this module at its core.\n\nIt's open source, and anyone can fork and add features and use the code as s/he likes.\n\nIf you're into it, please let me know if you liked it.\n\nPypi:\u00a0[https://pypi.org/project/stealthkit/](https://pypi.org/project/stealthkit/)\n\nGithub:\u00a0[https://github.com/theonlyanil/stealthkit](https://github.com/theonlyanil/stealthkit)\n\n**Target Audience**\n\nDevelopers who scrape websites blocked by anti-bot mechanisms.\n\n**Comparison**\n\nSo far I don't know of any pypi packages that does it better and with such simplicity.</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ipxhsk/i_published_my_third_opensource_python_package_to/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ipxhsk/i_published_my_third_opensource_python_package_to/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "11",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ixlsux/i_made_a_script_to_download_spotify_playlists/"
            },
            "content": "<p>I made a script to download Spotify playlists without login</p><p>Repo link: [https://github.com/invzfnc/spotify-downloader](https://github.com/invzfnc/spotify-downloader)\n\n**What my project does**  \nHi everyone! I created a lightweight script that lists tracks from a public Spotify playlist and downloads them from YouTube Music.\n\n**Key Features**\n\n* No premium required\n* No login or credentials required\n* Metadata is embedded in downloaded tracks\n* Downloads in higher quality (around 256 kbps)\n\n**Comparison/How is it different from other tools?**  \nI found many tools requiring users to sign up for Spotify Developer account and setup credentials before everything else. This script uses the public Spotify API to retrieve track details, so there's no need to login or setup!\n\n**How's the music quality?**  \nYouTube Music offers streams with higher bitrate (around 256 kbps) compared to YouTube (128 kbps). This script chooses and downloads the best quality audio from YouTube Music without taking up too much storage space.\n\n**Dependencies/Libraries?**  \nUsers are required to install innertube, SpotAPI, yt-dlp and FFmpeg for this script to work.\n\n**Target audience**  \nAnyone who is looking to save their Spotify playlists to local storage, without wanting to login to any platform, and wants something with decent bitrate (\\~256 kbps)\n\nIf you find this project useful or it helped you, feel free to give it a star! I'd really appreciate any feedback!</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ixlsux/i_made_a_script_to_download_spotify_playlists/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ixlsux/i_made_a_script_to_download_spotify_playlists/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "12",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ifu2sv/fastapi_deconstructed_anatomy_of_a_modern_asgi/"
            },
            "content": "<p>FastAPI Deconstructed: Anatomy of a Modern ASGI Framework</p><p>Recently I had the opportunity to talk about the FastAPI under the hood at PyCon APAC 2024. The title of the talk was \u201cFastAPI Deconstructed: Anatomy of a Modern ASGI Framework\u201d. Then, I thought why not have a written version of the talk. And, I have decided to write. Something like a blog post. So, here it is.\n\n[https://rafiqul.dev/blog/fastapi-deconstructed-anatomy-of-modern-asgi-framework](https://rafiqul.dev/blog/fastapi-deconstructed-anatomy-of-modern-asgi-framework)</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ifu2sv/fastapi_deconstructed_anatomy_of_a_modern_asgi/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ifu2sv/fastapi_deconstructed_anatomy_of_a_modern_asgi/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "13",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ime8ja/a_modern_python_repository_template_with_uv_and/"
            },
            "content": "<p>A Modern Python Repository Template with UV and Just</p><p>Hey folks, I wanted to share a Python repository template I've been using recently. It's not trying to be the ultimate solution, but rather a setup that works well for my needs and might be useful for others.\n\n**What My Project Does**\n\nIt's a repository template that combines several modern Python tools, with a focus on speed and developer experience:\n\n\\- UV for package management\n\n\\- Just as a command runner\n\n\\- Ruff for linting and formatting\n\n\\- Mypy for type checking\n\n\\- Docker support with a multi-stage build\n\n\\- GitHub Actions CI/CD setup\n\nThe main goal was to create a clean starting point that's both fast and maintainable.\n\n**Target Audience**\n\nThis template is meant for developers who want a production-ready setup but don't need all the bells and whistles of larger templates.\n\n**Comparison**\n\nThe main difference from other templates is the use of Just instead of Make as the command runner. While this means an extra installation step, Just offers several advantages, such as a cleaner syntax, better dependency handling and others.\n\nI also chose UV over pip for package management, but at this point I don't consider this as something unusual in the Python ecosystem.\n\nYou can find the template here: [https://github.com/GiovanniGiacometti/python-repo-template](https://github.com/GiovanniGiacometti/python-repo-template)\n\nHappy to hear your thoughts and suggestions for improvement!</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ime8ja/a_modern_python_repository_template_with_uv_and/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ime8ja/a_modern_python_repository_template_with_uv_and/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "14",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iyorr7/python_gave_me_the_chance_to_finally_execute_a/"
            },
            "content": "<p>Python gave me the chance to finally execute a personal project for something I actually needed</p><p>Not sure if this kind of post is allowed here but just wanted to celebrate this because it feels like a major milestone for me.\n\nI've been a software dev for about 10 years but in that time I have never come up with ideas of problems at home that I could solve with code. If I had an idea, there was already a solution out there or it felt like it would take way too much effort to build and implement in Typescript/.NET, which is what I use for my job.\n\nI recently picked up Python at work for a non-GUI data manipulation project and I was really surprised at how simple it is to set up and get going on. Feels like with the other languages I've tried out, you have to do so much configuration and build to even get off the ground, to the point where I've struggled in the past with tutorial courses because something doesn't work in configuring the IDE or installing packages, etc.\n\nWell the other day I was poking around with my home network software, trying to figure out if there was a way to get a notification when a certain device connects to the network - my son has been sneaking his school laptop into his room after bedtime to play games, and I absolutely did similar things as a kid but I have to at least try to be the responsible parent and make sure he's getting enough sleep, right? There wasn't any such functionality, but there was a REST API for checking on the status of clients connected to the network. I realized that I could use Python to set up a polling task that periodically pings that REST endpoint and checks if his Chromebook has connected.\n\nMan, it was so easy to spin up code to make periodic REST calls, keep track of the active status of the device, and then send an email to my cell provider to trigger a text message on my phone if it changes from inactive to active. The only thing that took me a little bit longer was figuring out how virtual environments work. I also need to circle back and do some cleanup and better exception handling, etc, but that's less important for a personal project that works great for now.\n\nPackaged it up, threw it on Github (my first ever Github commit!), cloned it to my Linux thin client, and just run the script. So easy, didn't have to follow millions of build or setup steps, and now I have a working \"product\" that does exactly what I need. So glad that I was introduced to Python, it really is a powerful language but at the same time so easy to jump into and make it work!</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iyorr7/python_gave_me_the_chance_to_finally_execute_a/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iyorr7/python_gave_me_the_chance_to_finally_execute_a/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "15",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1it29oi/logginggetlevelname_are_you_serious/"
            },
            "content": "<p>logging.getLevelName(): Are you serious?</p><p>I was looking for a function that would return the numerical value of a loglevel given as text. But I found only the reverse function per the [documentation](https://docs.python.org/3/library/logging.html):\n\n>logging.getLevelName(*level*) Returns the textual or numeric representation of logging level *level*.\n\nThat's exactly the reverse of what I need. But wait, there's more:\n\n>The *level* parameter also accepts a string representation of the level such as \u2018INFO\u2019. In such cases, this functions returns the corresponding numeric value of the level.\n\nSo a function that maps integers to strings, with a name that clearly implies that it returns strings, also can map strings to integers if you pass in a string. A function whose return type depends on the input type, neat!\n\nOK, so what happens when you pass in a value that has no number / name associated with it? Surely the function will return zero or raise a KeyError. But no:\n\n>If no matching numeric or string value is passed in, the string \u2018Level %s\u2019 % level is returned.\n\nFantastic! If I pass a string into a function called \"get..Name()\" it will return an integer on success and a string on failure!\n\nBut somebody, at some point, a sane person noticed that this is a mess:\n\n>Changed in version 3.4: In Python versions earlier than 3.4, this function could also be passed a text level, and would return the corresponding numeric value of the level. This undocumented behaviour was considered a mistake, and was removed in Python 3.4, but reinstated in 3.4.2 due to retain backward compatibility.\n\nOK, nice. But why on Earth didn't the people who reinstated the original functionality also add a function getLevelNumber()?\n\nYes, I did see this:\n\n>logging.getLevelNamesMapping()\n\n>Returns a mapping from level names to their corresponding logging levels. For example, the string \u201cCRITICAL\u201d maps to [`CRITICAL`](https://docs.python.org/3/library/logging.html#logging.CRITICAL). The returned mapping is copied from an internal mapping on each call to this function.\n\n>Added in version 3.11.\n\nOK, that's usable. But it also convoluted. Why do I need to get a whole deep copy of a mapping when the library could simply expose a getter function?\n\nAll of this can be worked around with a couple of lines of code. None of it is performance critical. I'm just puzzled by the fact that somebody thought this was good interface. Ex-VBA programmer maybe?\n\n**\\[EDIT\\]**\n\nSince many people suggested the `getattr(logging, 'INFO')` method: I didn't mention that I fell into this rabbit hole after declaring a custom loglevel whose name I wanted to use in another module.</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1it29oi/logginggetlevelname_are_you_serious/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1it29oi/logginggetlevelname_are_you_serious/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "16",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ilhbkk/fastapi_guard_a_fastapi_extension_to_secure_your/"
            },
            "content": "<p>FastAPI Guard - A FastAPI extension to secure your APIs</p><p>Hi everyone,\n\nI've published **FastAPI Guard** some time ago:\n\n**Documentation**: [rennf93.github.io/fastapi-guard/](https://rennf93.github.io/fastapi-guard/)\n\n**GitHub repo**: [github.com/rennf93/fastapi-guard](https://github.com/rennf93/fastapi-guard)\n\n**What is it?**\nFastAPI Guard is a security middleware for FastAPI that provides:\n- IP whitelisting/blacklisting\n- Rate limiting & automatic IP banning\n- Penetration attempt detection\n- Cloud provider IP blocking\n- IP geolocation via IPInfo.io\n- Custom security logging\n- CORS configuration helpers\n\nIt's licensed under MIT and integrates seamlessly with FastAPI applications.\n\n**Comparison to alternatives**:\n- `fastapi-security`: Focuses more on authentication, while FastAPI Guard provides broader network-layer protection\n- `slowapi`: Handles rate limiting but lacks IP analysis/geolocation features\n- `fastapi-limiter`: Pure rate limiting without security features\n- `fastapi-auth`: Authentication-focused without IP management\n\n**Key differentiators**:\n- Combines multiple security layers in single middleware\n- Automatic IP banning based on suspicious activity\n- Built-in cloud provider detection\n- Daily-updated IP geolocation database\n- Production-ready configuration defaults\n\n**Target Audience**:\nFastAPI developers needing:\n- Defense-in-depth security strategy\n- IP-based access control\n- Automated threat mitigation\n- Compliance with geo-restriction requirements\n- Penetration attempt monitoring\n\n**Feedback wanted**\n\nThanks!</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ilhbkk/fastapi_guard_a_fastapi_extension_to_secure_your/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ilhbkk/fastapi_guard_a_fastapi_extension_to_secure_your/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "17",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iif99x/must_know_python_libraries_new_and_old/"
            },
            "content": "<p>Must know Python libraries, new and old?</p><p>I have 4YOE as a Python backend dev and just noticed we are lagging behind at work. For example, I wrote a validation library at the start and we have been using it for this whole time, but recently I saw Pydantic and although mine has most of the functionality, Pydantic is much, much better overall. I feel like im stagnating and I need to catch up. We don't even use Dataclasses. I recently learned about Poetry which we also don't use. We use pandas, but now I see there is polars. Pls help.\n\n\nPlease share: TLDR - what are the most popular must know python libraries? Pydantic, poetry? </p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iif99x/must_know_python_libraries_new_and_old/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iif99x/must_know_python_libraries_new_and_old/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "18",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iqytkf/python_type_hints_and_why_you_should_use_them/"
            },
            "content": "<p>Python Type Hints and why you should use them.</p><p>[https://blog.jonathanchun.com/2025/02/16/to-type-or-not-to-type/](https://blog.jonathanchun.com/2025/02/16/to-type-or-not-to-type/)\n\nI wrote this blog post as I've seen a lot of newer developers complain about Type hints and how they seem unnecessary. I tried to copy-paste a short excerpt from the blog post here but it kept detecting it as a question which is not allowed, so decided to leave it out.\n\nI know there's plenty of content on this topic, but IMO there's still way too much untyped Python code!</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iqytkf/python_type_hints_and_why_you_should_use_them/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iqytkf/python_type_hints_and_why_you_should_use_them/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "19",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ixryec/anyone_used_uv_package_manager_in_production/"
            },
            "content": "<p>Anyone used UV package manager in production</p><p>Is it reliable to use it in production as it is comparatively new in the market.\n\nAlso has it any disadvantages that i should be aware of before pitching it to my manager.\n\nHelp would be appreciated.\n\nAny other tool suggestions also appreciated </p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ixryec/anyone_used_uv_package_manager_in_production/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ixryec/anyone_used_uv_package_manager_in_production/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "20",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iipilb/python_pandas_library_not_accepted_at_workplace/"
            },
            "content": "<p>Python Pandas Library not accepted at workplace - is it normal?</p><p>I joined a company 7-8 months ago as an entry level junior dev, and recently was working on some report automation tasks for the business using Python Pandas library.\n\nI finished the code, tested on my local machine - works fine. I told my team lead and direct supervisor and asked for the next step, they told me to work with another team (Technical Infrastructure) to test the code in a lower environment server. Fine, I went to the TI Team, but then was told NumPy and Pandas are installed in the server, but the libraries are not running properly.\n\nThey pulled in another team C to check what's going on, and found out is that the NumPy Lib is deprecated which is not compatible with Pandas. Ok, how to fix it? \"Well, you need to go to team A and team B and there's a lot of process that needs to go through...\" \"It's a project - problems might come along the way, one after the other\",\n\nand after I explained to them Pandas is widely used in tasks related to data analytics and manipulation, and will also be beneficial for the other developers in the future as well, I explained the same idea to my team, their team, even team C. My team and team C seems to agree with the idea, they even helped to push the idea, but the TI team only responded \"I know, but how much data analytics do we do here?\"\n\nI'm getting confused - am I being crazy here? Is it normal Python libraries like Pandas is not accepted at workplace?\n\nEDIT: Our servers are not connected to the internet so pip is not an option - at least this is what I was told\n\nEDIT2: I\u2019m seeing a lot of posts recommending Docker, would like to provide an update: this is actually discussed - my manager sets up a meeting with TI team and Team C. What we got is still No\u2026 One is Docker is currently not approved in our company (I tried to request install it anyway, but got the \u201cthere\u2019s the other set of process you need just to get it approved by the company and then you can install it\u2026\u201d)\nTwo is a senior dev from Team C brought up an interesting POC: Use Docker to build a virtual environment with all the needed libs that can be used across all Python applications, not the containers. However with that approach, (didn\u2019t fully understand the full conversation but here is the gist) their servers are going to have a hardware upgrade soon, so before the upgrade, \u201cwe are not ready for that yet\u201d\u2026\n\nSide Note: Meanwhile wanted to thank everyone in this thread! Learning a lot from this thread, containers, venv, uv, etc. I know there\u2019s still a lot I need to learn, but still, all of this is really eye-opening for me\n\nFINAL EDIT: After rounds of discussions with the TI Team, Team C, and my own team management with all the options (containers, upgrade the libraries and dependencies, even use Python 2.7), we (my management and the other teams) decided the best option will be me to rewrite all my programs using PySpark since 1. Team C is already using it, 2. Maybe no additional work needed for the other teams.\nFrustrated, I tried to fight back one last time with my own management today, but was told \u201cThis is the corporate. Not the first time we had this kind of issues\u201d\nI love to learn new things in general, but still in this case, frustrated.</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iipilb/python_pandas_library_not_accepted_at_workplace/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iipilb/python_pandas_library_not_accepted_at_workplace/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "21",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ije2ul/my_python_based_selfhosted_pdf_manager_viewer_and/"
            },
            "content": "<p>My python based selfhosted PDF manager, viewer and editor reached 600 stars on github</p><p>Hi r/Python,\n\nI am the developer of PdfDing - a selfhosted PDF manager, viewer and editor offering a seamless user experience on multiple devices. You can find the repo\u00a0[here](https://github.com/mrmn2/PdfDing).\n\nToday I reached a big milestone as PdfDing reached over 600 stars on github. A good portion of these stars probably comes from being included in the *favorite selfhosted apps launched in 2024* on [selfh.st](https://selfh.st/2024-favorite-new-apps/).\n\n**What My Project Does**\n\nPdfDing is a selfhosted PDF manager, viewer and editor. Here is a quick overview over the project\u2019s features:\n\n* Seamless browser based PDF viewing on multiple devices. Remembers current position - continue where you stopped reading\n* Stay on top of your PDF collection with multi-level tagging, starring and archiving functionalities\n* Edit PDFs by adding annotations, highlighting and drawings\n* Clean, intuitive UI with dark mode, inverted color mode and custom theme colors\n* SSO support via OIDC\n* Share PDFs with an external audience via a link or a QR Code with optional access control\n* Markdown Notes\n* Progress bars show the reading progress of each PDF at a quick glance\n\nPdfDing heavily uses Django, the Python based web framework. Other than this the tech stack includes tailwind css, htmx, alpine js and pdf.js.\n\n**Target Audience**\n\n* Homelabs\n* Small businesses\n* Everyone who wants to read PDFs in style :)\n\n**Comparison**\n\n* PdfDing is all about reading and organizing your PDFs while being simple and intuitive. All features are added with the goal of improving the reading experience or making the management of your PDF collection simpler.\n* Other solutions were either too resource hungry, do not allow reading Pdfs in the browser on mobile devices (they'll download the files) or do not allow individual users to upload files.\n\n**Conclusion**\n\nAs always I am happy if you star the [repo](https://github.com/mrmn2/PdfDing) or if someone wants to contribute.</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ije2ul/my_python_based_selfhosted_pdf_manager_viewer_and/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ije2ul/my_python_based_selfhosted_pdf_manager_viewer_and/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "22",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ihl5fy/tach_a_python_tool_to_enforce_dependencies/"
            },
            "content": "<p>Tach - A Python tool to enforce dependencies</p><p>Source: [https://github.com/gauge-sh/tach](https://github.com/gauge-sh/tach)\n\nPython allows you to import and use anything, anywhere. Over time, this results in modules that were intended to be separate getting tightly coupled together, and domain boundaries breaking down.\n\nWe experienced this first-hand at a unicorn startup, where the entire engineering team paused development for over a year in an attempt to split up tightly coupled packages into independent microservices. This ultimately failed, and resulted in the CTO getting fired.\n\nThis problem occurs because:\n\n* It's much easier to add to an existing package rather than create a new one\n* Junior devs have a limited understanding of the existing architecture\n* External pressure leading to shortcuts and overlooking best practices\n\nAttempts we've seen to fix this problem always came up short. A patchwork of solutions would attempt to solve this from different angles, such as developer education, CODEOWNERs, standard guides, refactors, and more. However, none of these addressed the root cause.\n\n# What My Project Does\n\nWith [Tach](https://github.com/gauge-sh/tach), you can:\n\n1. Declare your modules ([`tach mod`](https://docs.gauge.sh/usage/commands#tach-mod))\n2. Automatically declare dependencies ([`tach sync`](https://docs.gauge.sh/usage/commands#tach-sync))\n3. Enforce those dependencies ([`tach check`](https://docs.gauge.sh/usage/commands#tach-check))\n4. Visualize those dependencies ([`tach show`](https://docs.gauge.sh/usage/commands#tach-show) and [`tach report`](https://docs.gauge.sh/usage/commands#tach-report))\n\nYou can also enforce a [public interface](https://docs.gauge.sh/usage/interfaces) for each module, and [deprecate dependencies](https://docs.gauge.sh/usage/deprecate) over time.\n\n\n# Target Audience\n\nDevelopers working on large Python monoliths\n\n# Comparison\n\n* import linter - similar but more specifically focused on import rules\n* build systems - bazel, pants, buck, etc. More powerful but much more heavy and waaaay more slow\n\nI'd love if you try it out on your project and let me know if you find it useful!</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ihl5fy/tach_a_python_tool_to_enforce_dependencies/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ihl5fy/tach_a_python_tool_to_enforce_dependencies/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "23",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ixz0tk/tach_visualize_untangle_your_codebase/"
            },
            "content": "<p>Tach - Visualize + Untangle your Codebase</p><p>Hey everyone! We're building Gauge, and today we wanted to share our open source tool, [Tach](https://github.com/gauge-sh/tach), with you all.\n\n**What My Project Does**\n\n[Tach](https://github.com/gauge-sh/tach) gives you visibility into your Python codebase, as well as the tools to fix it. You can instantly visualize your dependency graph, and see how modules are being used. Tach also supports enforcing first and third party dependencies and interfaces.\n\nHere\u2019s a quick demo: [https://www.youtube.com/watch?v=ww\\_Fqwv0MAk](https://www.youtube.com/watch?v=ww_Fqwv0MAk)\n\n[Tach](https://github.com/gauge-sh/tach) is:\n\n* Open source (MIT) and completely free\n* Blazingly fast (written in Rust \ud83e\udd80)\n* In use by teams at NVIDIA, PostHog, and more\n\nAs your team and codebase grows, code get tangled up. This hurts developer velocity, and increases cognitive load for engineers. Over time, this silent killer can become a show stopper. Tooling breaks down, and teams grind to a halt. My co-founder and I experienced this first-hand. We're building the tools that we wish we had.\n\nWith [Tach](https://github.com/gauge-sh/tach), you can visualize your dependencies to understand how badly tangled everything is. You can also set up enforcement on the existing state, and deprecate dependencies over time.\n\n**Comparison** One way [Tach](https://github.com/gauge-sh/tach) differs from existing systems that handle this problem (build systems, import linters, etc) is in how quick and easy it is to adopt incrementally. We provide a [sync command](https://docs.gauge.sh/usage/commands#tach-sync) that instantaneously syncs the state of your codebase to [Tach](https://github.com/gauge-sh/tach)'s configuration.\n\nIf you struggle with dependencies, onboarding new engineers, or a massive codebase, [Tach](https://github.com/gauge-sh/tach) is for you!\n\n**Target Audience** We built it with developers in mind - in Rust for performance, and with clean integrations into Git, CI/CD, and IDEs.\n\nWe'd love for you to give Tach a \u2b50 and try it out!</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ixz0tk/tach_visualize_untangle_your_codebase/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ixz0tk/tach_visualize_untangle_your_codebase/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "24",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ihsezp/python_3132_released/"
            },
            "content": "<p>Python 3.13.2 Released</p><p>https://www.python.org/downloads/release/python-3132/\n\n> Python 3.13 is the newest major release of the Python programming language, and it contains many new features and optimizations compared to Python 3.12. 3.13.2 is the latest maintenance release, containing almost 250 bugfixes, build improvements and documentation changes since 3.13.1. \n\nIt does not list precisely what bugs were fixed. Does anyone have a list?</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ihsezp/python_3132_released/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ihsezp/python_3132_released/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "25",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iz0qxe/why_not_just_plot_everything_in_numpy_p2/"
            },
            "content": "<p>Why not just plot everything in numpy?! P.2.</p><p>Thank you all for overwhelmingly positive feedback to my\u00a0[last post](https://www.reddit.com/r/Python/comments/1f7jfgd/why_not_just_get_your_plots_in_numpy/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)!\n\n&nbsp;\n\nI've finally implemented what I set out to do there:\u00a0[https://github.com/bedbad/justpyplot](https://github.com/bedbad/justpyplot)\u00a0([docs](https://justpyplot.readthedocs.io/en/latest/#justpyplot.justpyplot.plot))\n\n&nbsp;\n\nA single plot() function API:\n\n`plot(values:np.ndarray, grid_options:dict, figure_options:dict, ...) -> (figures,\u00a0grid,\u00a0axis, labels)`\n\nYou can now overlay, mask, transform, render full plots everywhere you want with single rgba plot() API\n\nIt\n\n* Still runs faster then matplotlib, 20x-100x times:timer \"full justpyplot + rendering\": avg 382 \u00b5s \u00b1 135 \u00b5s, max 962 \u00b5s\n* Flexible, values are your stacked points and grid\\_options, figure\\_options are json-style dicts that lets you control all the details of the graph parts design without bloating the 1st level interface\n* Composable - works well with OpenCV, Jupyter Notebooks, pyqtgraph - you name it\n* Smol - less then 20k memory and 1000 lines of core vectorized code for plotting, because it's\n* No dependencies. Yes, really, none except numpy. If you need plots in Jupyter you have Pillow or alike to display ports, if you need graphs in OpenCV you just install cv2 and it has adaptors to them but no dependencies standalone, so you don't loose much at all installing it\n* Fully vectorized - yes it has no single loop in core code, it even has it's own text literals rendering, not to mention grid, figures, labels all done without a single loop which is a real brain teaser\n\nWhat my project does? How does it compare?\n\nStandard plot tooling as matplotlib, seaborn, plotly etc achieve plot control flexibility through monstrous complexity. The way to compare it is this lib takes the exact opposite approach of pushing the design complexity down to styling dicts and giving you the control through clear and minimalistic way of manipulating numpy arrays and thinking for yourself.\n\nTarget Audience?\n\nI initially scrapped it for computer vision and robotics where I needed to stick multiple graphs on camera view to see how the thing I'm messing with in real-world is doing. Judging by stars and comments the audience may grow to everyone who wants to plot simply and efficiently in Python.\n\nI've tried to implement most of the top redditors suggestions about it except\u00a0[incapsulating it in Array API](https://www.reddit.com/r/Python/comments/1f7jfgd/comment/ll82qok/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)\u00a0beyond just numpy which would be really cool idea for things like ML pluggable graphs and making it 3D, due to the amount though it's still on the back burner.\n\nLet me know which direction it really grow!</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iz0qxe/why_not_just_plot_everything_in_numpy_p2/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iz0qxe/why_not_just_plot_everything_in_numpy_p2/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "26",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iondou/a_new_sorting_algorithm_for_2025_faster_than/"
            },
            "content": "<p>A new sorting algorithm for 2025, faster than Powersort!</p><p>tl;dr It's faster than Python's Default sorted() function, Powersort, and it's not even optimized yet.\n\nOriginal post here: [https://www.reddit.com/r/computerscience/comments/1ion02s/a\\_new\\_sorting\\_algorithm\\_for\\_2025\\_faster\\_than/](https://www.reddit.com/r/computerscience/comments/1ion02s/a_new_sorting_algorithm_for_2025_faster_than/)</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iondou/a_new_sorting_algorithm_for_2025_faster_than/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iondou/a_new_sorting_algorithm_for_2025_faster_than/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "27",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ip3pvd/python_developers_how_are_you_finding_jobs_in_2025/"
            },
            "content": "<p>Python Developers: How Are You Finding Jobs in 2025?</p><p>Hey everyone,\n\nI\u2019ve been curious about the current job market for Python developers. With AI tools changing the landscape, how are you all finding work?\n\n* Freelancing platforms Upwork and Fiverr still viable?\n* How important is having a GitHub portfolio (personal projects)?\n* What strategies have worked for landing clients or job offers?\n\nI have already tried Fiverr and Upwork with no luck, so I\u2019m looking for alternative ways to land work. Would love to hear your experiences, especially if you\u2019ve recently landed a role or struggled in the process. Let\u2019s help each other out!</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ip3pvd/python_developers_how_are_you_finding_jobs_in_2025/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ip3pvd/python_developers_how_are_you_finding_jobs_in_2025/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "28",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ir9xk7/terminaltexteffects_tte_version_0120/"
            },
            "content": "<p>TerminalTextEffects (TTE) version 0.12.0</p><p>I saw the word '*effects*', just give me GIFs\n\nUnderstandable, visit the [Effects Showroom](https://chrisbuilds.github.io/terminaltexteffects/showroom/) first. Then come back if you like what you see.\n\n**What My Project Does**\n\nTerminalTextEffects (TTE) is a terminal visual effects engine. TTE can be installed as a system application to produce effects in your terminal, or as a Python library to enable effects within your Python scripts/applications. TTE includes a growing library of built-in effects which showcase the engine's features.\n\n**Audience**\n\nTTE is a terminal toy (and now a Python library) that anybody can use to add visual flair to their terminal or projects. It works best in Linux but is functional in the new Windows Terminal.\n\n**Comparison**\n\nI don't know of anything quite like this.\n\n**Version 0.12.0**\n\nIt's been almost nine months since I shared this project here. Since then there have been two significant updates. The first added the Matrix effect as well as canvas anchoring and text anchoring. More information is available in the release write-up here: \n\n[0.11.0 - Enter the Matrix](https://chrisbuilds.github.io/terminaltexteffects/changeblog/changeblog_0.11.0/)\n\nand the latest release features a few new effects, color sequence parsing and support for background colors. The write-up is available here:\n\n[0.12.0 - Color Parsing](https://chrisbuilds.github.io/terminaltexteffects/changeblog/changeblog_0.12.0/)\n\nHere's the repo: https://github.com/ChrisBuilds/terminaltexteffects\n\nCheck it out if you're interested. I appreciate new ideas and feedback.</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ir9xk7/terminaltexteffects_tte_version_0120/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ir9xk7/terminaltexteffects_tte_version_0120/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "29",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iw3lnu/i_made_a_python_app_that_turns_your_figma_design/"
            },
            "content": "<p>I made a Python app that turns your Figma design into code</p><p>\ud83d\udd17 Link \u2014 [https://github.com/axorax/tkforge](https://github.com/axorax/tkforge)\n\n# What My Project Does\n\nTkForge is a Python app that allows you to turn your Figma design into Python tkinter code. So, you can make a GUI design in Figma and use specific names like \"textbox\", \"circle\", \"image\" and more for interactable elements then use TkForge to get the code for a fully functional working GUI app from your design.\n\nAnd it's **free, open-source** and regularly maintained!\n\n# Target Audience\n\nTkForge is made for anyone who wants to make a GUI with Python easily and efficiently. It's fast and you can make some really complex and beautiful GUI's with it.\n\n# Comparison\n\nThere's another project similar to TkForge called Tkinter Designer. Personally without being biased, I think TkForge is better. TkForge supports everything Tkinter Designer does and more. TkForge generates better code, supports more elements, allows you to add placeholder text (which you can't by default in tkinter), automatically sets foreground color and a lot more! Placeholder text and foreground color generation is a bit buggy though.  I use TkForge for most of my tkinter projects. You can get help in the Discord server.\n\n# Updates\n\nI updated the app to support multiple frames, fixed a lot of previous bugs and added checks for new updates!\n\nThanks for reading! \ud83d\ude04</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iw3lnu/i_made_a_python_app_that_turns_your_figma_design/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iw3lnu/i_made_a_python_app_that_turns_your_figma_design/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "30",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ioo4yd/bulletproof_wakewordkeyword_spotting/"
            },
            "content": "<p>Bulletproof wakeword/keyword spotting</p><p>**Project overview and target audience**\n\nHi All, I am Tyler Troy, a co-founder at Look Deep Health Inc. We are a\u00a0healthcare startup that\u00a0provides\u00a0a hardware/software platform for AI-enhanced video monitoring and virtual care solutions to hospitals. One of our product features involves the detection of a safety word for staff to get help while under threat of intimidation or violence (sadly workplace violence rates are among the highest for health care workers). As such we needed a bullet proof model with a low false detection rate and that could run with a low footprint on our embedded device. Below is a brief recap of my project experience. I'm sharing here in the hopes to save you some headache and time in your own keyword detection projects.\u00a0\n\nWhen I started researching this project I stumbled across a r/learnpython post\u00a0asking for suggestions for wakeword/keyword detection models/services. Among the suggestions were OpenWakeWords, Porcupine (PicoVoice), and DaVoice. For the TL;DR readers, the models from [DaVoice](https://davoice.io/) were the best performers in both positive detection and false detection rates. It was also very easy to work with the DaVoice team who were supportive and flexible over the course of the project and it didn't hurt that they were significantly\u00a0cheaper than other competitors.\u00a0\u00a0Check out their python implementation at https://github.com/frymanofer/Python\\_WakeWordDetection. You an also find implementations for a dozen or so other languages.\n\n**A comparison of keyword detection libraries**\n\nMy first foray was into using\u00a0[openwakewords](https://github.com/dscripka/openWakeWord)\u00a0(OWW). Overall this is a great free library that shows commendable\u00a0performance and a simple retraining process however, the detection rate was too low and attempts\u00a0at retraining the model with custom TTS samples (see https://github.com/coqui-ai/TTS) didn't greatly improve matters and above all the false positive rate was too high, even when combined with voice activity detection (VAD). It's possible that we could have dedicated six months to honing the performance of OWW but we have very few resources and that would have meant holding up other projects.\u00a0\n\nNext I tried\u00a0[Porcupine](https://picovoice.ai/platform/porcupine/)\u00a0from PicoVoice. Implementation of a PoC was super easy and model performance is good but we did get a few false positives. Also they are just too expensive and frankly they were not very supportive of us as a small start up (fair enough, bigger fish to fry I guess). Furthermore their model requires one license key per device and we didn't want the headache of managing keys across our thousands of devices. Also as you'll see below, the performance just isn't as good and there is nothing you can do to make it better because there is no possibility\u00a0of fine-tuning or retraining.\u00a0\n\nFinally, we contacted DaVoice, and I can confidently say that DaVoice is the clear winner. Their models have the best positive detection rates (see table), and most critically,\u00a0*zero false positives*\u00a0after one month of testing! In hospital settings, false alerts are unacceptable\u2014they waste valuable time and can compromise patient care.\u00a0With DaVoice, we experienced\u00a0zero false alerts, ensuring absolute reliability. In contrast, With Picovoice we experienced\u00a0several false alerts over the course of testing, making it problematic for critical environments like hospitals.\n\n**Table 1: A comparison of model performance on custom keywords**\n\n|Library|Positive Detection Rate|\n|:-|:-|\n|DaVoice|0.992481|\n|Porcupine (Picovoice)|0.924812|\n|OpenWakeWords|0.686567|</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ioo4yd/bulletproof_wakewordkeyword_spotting/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ioo4yd/bulletproof_wakewordkeyword_spotting/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "31",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iidlui/fastplotlib_a_new_gpuaccelerated_fast_and/"
            },
            "content": "<p>fastplotlib, a new GPU-accelerated fast and interactive plotting library that leverages WGPU</p><p>What My Project Does\n\nFastplotlib is a next-gen plotting library that utilizes Vulkan, DX12, or Metal via WGPU, so it is very fast! We built this library for rapid prototyping and large-scale exploratory scientific visualization. This makes fastplotlib a great library for designing and developing machine learning models, especially in the realm of computer vision. Fastplotlib works in jupyterlab, Qt, and glfw, and also has optional imgui integration.\n\nGitHub repo: https://github.com/fastplotlib/fastplotlib \n\nTarget audience:\n\nScientific visualization and production use. \n\nComparison:\n\nUses WGPU which is the next gen graphics stack, unlike most gpu accelerated libs that use opengl. We've tried very hard to make it easy to use for interactive plotting. \n\n\nOur recent talk and examples gallery are a great way to get started! \nTalk on youtube: https://www.youtube.com/watch?v=nmi-X6eU7Wo \nExamples gallery: https://fastplotlib.org/ver/dev/_gallery/index.html \n\nAs an aside, fastplotlib is not related to matplotlib in any way, we describe this in our FAQ: https://fastplotlib.org/ver/dev/user_guide/faq.html#how-does-fastplotlib-relate-to-matplotlib\n\nIf you have any questions or would like to chat, feel free to reach out to us by posting a GitHub Issue or Discussion! We love engaging with our community! \n</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iidlui/fastplotlib_a_new_gpuaccelerated_fast_and/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iidlui/fastplotlib_a_new_gpuaccelerated_fast_and/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "32",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iyt9vz/cursed_decorators/"
            },
            "content": "<p>Cursed decorators</p><p>https://gist.github.com/bolu61/ee92a143692c991cf7a44c7bf4f8a9b6\n\nI was procrastinating at work, don't know what to think about this.</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iyt9vz/cursed_decorators/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iyt9vz/cursed_decorators/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "33",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ipxf6t/introducing_kreuzberg_v20_an_optimized_text/"
            },
            "content": "<p>Introducing Kreuzberg V2.0: An Optimized Text Extraction Library</p><p>I introduced Kreuzberg a few weeks ago in [this post](https://www.reddit.com/r/Python/comments/1if3axy/introducing_kreuzberg_a_simple_modern_library_for/).\n\nOver the past few weeks, I did a lot of work, released 7 minor versions, and generally had a lot of fun. I'm now excited to announce the release of v2.0!\n\n## What's Kreuzberg?\n\n[Kreuzberg](https://github.com/Goldziher/kreuzberg) is a text extraction library for Python. It provides a unified async/sync interface for extracting text from PDFs, images, office documents, and more - all processed locally without external API dependencies. Its main strengths are:\n\n- Lightweight (has few curated dependencies, does not take a lot of space, and does not require a GPU)\n- Uses optimized async modern Python for efficient I/O handling\n- Simple to use\n- Named after my favorite part of Berlin\n\n## What's New in Version 2.0?\n\nVersion two brings significant enhancements over version 1.0:\n\n- Sync methods alongside async APIs\n- Batch extraction methods\n- Smart PDF processing with automatic OCR fallback for corrupted searchable text\n- Metadata extraction via Pandoc\n- Multi-sheet support for Excel workbooks\n- Fine-grained control over OCR with `language` and `psm` parameters\n- Improved multi-loop compatibility using `anyio`\n- Worker processes for better performance\n\nSee the full [changelog here](https://github.com/Goldziher/kreuzberg/releases/tag/v2.0.0).\n\n## Target Audience\n\nThe library is useful for anyone needing text extraction from various document formats. The primary audience is developers who are building RAG applications or LLM agents.\n\n## Comparison\n\nThere are many alternatives. I won't try to be anywhere near comprehensive here. I'll mention three distinct types of solutions one can use:\n\n1. Alternative OSS libraries in Python. The top three options here are:\n   - Unstructured.io: Offers more features than Kreuzberg, e.g., chunking, but it's also much much larger. You cannot use this library in a serverless function; deploying it dockerized is also very difficult.\n   - Markitdown (Microsoft): Focused on extraction to markdown. Supports a smaller subset of formats for extraction. OCR depends on using Azure Document Intelligence, which is baked into this library.\n   - Docling: A strong alternative in terms of text extraction. It is also very big and heavy. If you are looking for a library that integrates with LlamaIndex, LangChain, etc., this might be the library for you.\n\n2. Alternative OSS libraries not in Python. The top options here are:\n   - Apache Tika: Apache OSS written in Java. Requires running the Tika server as a sidecar. You can use this via one of several client libraries in Python (I recommend [this client](https://github.com/stumpylog/tika-client)).\n   - Grobid: A text extraction project for research texts. You can run this via Docker and interface with the API. The Docker image is almost 20 GB, though.\n\n3. Commercial APIs: There are numerous options here, from startups like LlamaIndex and unstructured.io paid services to the big cloud providers. This is not OSS but rather commercial.\n\nAll in all, Kreuzberg gives a very good fight to all these options. You will still need to bake your own solution or go commercial for complex OCR in high bulk. The two things currently missing from Kreuzberg are layout extraction and PDF metadata. Unstructured.io and Docling have an advantage here. The big cloud providers (e.g., Azure Document Intelligence and AWS Textract) have the best-in-class offerings.\n\nThe library requires minimal system dependencies (just Pandoc and Tesseract). Full documentation and examples are available in the repo.\n\nGitHub: https://github.com/Goldziher/kreuzberg. If you like this library, please star it \u2b50 - it makes me warm and fuzzy.\n\nI am looking forward to your feedback!</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ipxf6t/introducing_kreuzberg_v20_an_optimized_text/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ipxf6t/introducing_kreuzberg_v20_an_optimized_text/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "34",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ikhmtd/i_have_published_fastsqla_an_sqlalchemy_extension/"
            },
            "content": "<p>I have published FastSQLA - an SQLAlchemy extension to FastAPI</p><p>Hi folks,\n\nI have published FastSQLA:\n\n* Documentation: [https://hadrien.github.io/FastSQLA/](https://hadrien.github.io/FastSQLA/)\n* Github repo: [https://github.com/hadrien/fastsqla](https://github.com/hadrien/fastsqla)\n\n# What is it?\n\n**FastSQLA** is an SQLAlchemy 2.0+ extension for FastAPI.\n\nIt streamlines the configuration and async connection to relational databases using SQLAlchemy 2.0+.\n\nIt offers built-in & customizable pagination and automatically manages the SQLAlchemy session lifecycle following SQLAlchemy's best practices.\n\nIt is licenced under the MIT Licence.\n\n# Comparison to alternative\n\n* fastapi-sqla allows both sync and async drivers. **FastSQLA** is exclusively async, it uses fastapi dependency injection paradigm rather than adding a middleware as fastapi-sqla does.\n* fastapi-sqlalchemy: It hasn't been released since September 2020. It doesn't use FastAPI dependency injection paradigm but a middleware.\n* SQLModel: FastSQLA is not an alternative to SQLModel. FastSQLA provides the SQLAlchemy configuration boilerplate + pagination helpers. SQLModel is a layer on top of SQLAlchemy. I will eventually add SQLModel compatibility to FastSQLA so that it adds pagination capability and session management to SQLModel.\n\n# Target Audience\n\nIt is intended for Web API developers who use or want to use python 3.12+, FastAPI and SQLAlchemy 2.0+, who need async only sessions and who are looking to following SQLAlchemy best practices, latest python, FastAPI & SQLAlchemy. \n\nI use it in production on revenue-making projects.\n\n# Feedback wanted\n\nI would love to get feedback:\n\n* Are there any features you'd like to see added?\n* Is the documentation clear and easy to follow?\n* What\u2019s missing for you to use it?\n\nThanks for your attention, enjoy the weekend!\n\nHadrien</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ikhmtd/i_have_published_fastsqla_an_sqlalchemy_extension/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ikhmtd/i_have_published_fastsqla_an_sqlalchemy_extension/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "35",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1irye5t/i_created_a_python_price_tracker/"
            },
            "content": "<p>I created a Python Price Tracker</p><p>The link of the project is\u00a0[here](https://github.com/remeedev/Price-Watchlist).\n\n**What My Project Does**\n\nIt automatically reads the price from certain shop links and returns the price to the user, notifying them of price changes automatically.\n\nI am currently trying to buy a pc ($500 pc but still) and since I am saving and I am scared that the prices will be constantly changing I created a program that automatically updates an excel and sends me a message, through the telegram API of possible price changes.\n\nIt has the following features:\n\n\\- Five minute check of all products and prices.\n\n\\- Automatic message sending, along with easy to follow instructions to configure the telegram bot.\n\n\\- Automatic updating of the excel sheet\n\nThe only downside is that since I am web scraping some stores are still not available in the price\\_getter file.\n\nIt is just a side project but if anyone wants me to add a store to retrieve the prices from there I will keep on updating it for a while!\n\n**Target Audience**\n\nFor this project I think people saving up for items in certain shops could use this project to track their price in real time.\n\nThe code uses webscraping, Telegram API, and google sheets API\n\nYou could just implement it as a module in other code projects.\n\nLink to the repo: [https://github.com/remeedev/Price-Watchlis](https://github.com/remeedev/Price-Watchlist)t</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1irye5t/i_created_a_python_price_tracker/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1irye5t/i_created_a_python_price_tracker/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "36",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ijrewd/pypy_v7318_release/"
            },
            "content": "<p>PyPy v7.3.18 release</p><p>>Here's the blog post about the PyPY 7.3.18 release that came out yesterday. Thanks to @matti-p.bsky.social, our release manager! This the first version with 3.11 support (beta only so far). Two cool other features in the thread below.\n\n[https://pypy.org/posts/2025/02/pypy-v7318-release.html](https://pypy.org/posts/2025/02/pypy-v7318-release.html)</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ijrewd/pypy_v7318_release/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ijrewd/pypy_v7318_release/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "37",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1izf8wd/matrixfuncs_a_fast_and_flexible_python_package/"
            },
            "content": "<p>Matrixfuncs \u2013 A Fast and Flexible Python Package for Matrix Functions</p><p>\ud83d\ude80 **New Release: matrixfuncs \u2013 A Fast and Flexible Python Package for Matrix Functions**\n\nHey everyone,\n\n# Target Audience\n\nI just released a new version of `matrixfuncs`, a lightweight Python package for computing matrix functions efficiently. The target audiences are researchers and computer scientists. If you work with linear algebra, numerical methods, or recurrence relations, this might be useful for you!\n\nThe project is still in beta, but I\u2019ve added an example (`examples/many_frequencies.py`) that:\n\n* Samples a random function and determines the recurrence relation between the sampled points.\n* Uses `matrixfuncs` to generate a function that solves the recurrence relation anywhere\u2014including between sampled data points.\n\n\ud83d\udcca Example Plot: [Example](https://imgur.com/a/33y9Pbx)\n\n# \ud83d\udd0d Comparison\n\nAn equivalent solution could be implemented with `scipy.linalg.fractional_matrix_power`, but `matrixfuncs` has two key advantages:\n\n1\ufe0f\u20e3 Memory & Speed Optimizations\n\n* The library uses a special representation that allows changing the order of function computation and matrix multiplication.\n* This means in expressions like `A @ f(M)`, you can evaluate `@` before computing `f(M)`.\n* As a result, it requires less memory and scales better if you need to evaluate many functions at the same matrix , since it avoids storing large matrices.\n\n# \u26a1 What My Project Does As Well\n\n**Supports Arbitrary Functions**\n\n* SciPy provides matrix functions for common cases (`expm, logm, sqrtm`, etc.), but `matrixfuncs` allows you to apply any function to a matrix.\n* For example, you can compute the zeta function of a random matrix\u2014something SciPy doesn\u2019t support.\n* If you have a real-world use case where SciPy falls short, let me know, and I might include an example in a future update!\n\nBetter Accuracy: `scipy.linalg.funm` has known accuracy issues, especially for large eigenvalues ([see this scipy-issue](https://github.com/scipy/scipy/issues/21803#issuecomment-2455666759)). While I haven't done formal benchmarks yet, initial tests show that `matrixfuncs` produces results that align well with SciPy\u2019s specialized functions (`expm, logm, sqrtm`, etc.).\n\n# \u2728 What's New?\n\n\u2705 Improved performance for common matrix functions (exp, log, power, etc.)  \n\u2705 Better handling of matrix deficiencies  \n\u2705 Extended documentation and examples\n\n# \ud83d\udd17 Check it out:\n\n* GitHub: [github.com/nextdorf/matrix-functions](https://github.com/nextdorf/matrix-functions)\n* PyPI: [pypi.org/project/matrixfuncs](https://pypi.org/project/matrixfuncs/)\n\nWould love to hear your thoughts\u2014feedback & feature requests are welcome! \ud83d\ude80</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1izf8wd/matrixfuncs_a_fast_and_flexible_python_package/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1izf8wd/matrixfuncs_a_fast_and_flexible_python_package/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "38",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ih5238/pytestmock_mocking_in_pytest_test_code/"
            },
            "content": "<p>pytest-mock : Mocking in pytest - Test & Code</p><p>https://testandcode.com/episodes/pytest-mock\n\npytest-mock is currently the #3 pytest plugin. \n\n- Why the pytest-mock plugin is awesome\n- What is mocking, patching, and monkey patching\n- What, if any, is the difference between mock, fake, spy, stub. \n- Why we might need these in testing\n- Some history of mock in Python and how mock became unittest.mock\n- Using mocker.patch, mocker.spy, and mocker.stub\n- Why pytest-mock is awesome and why you might want to use it over straight unittest.mock</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ih5238/pytestmock_mocking_in_pytest_test_code/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ih5238/pytestmock_mocking_in_pytest_test_code/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "39",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iqvcec/looking_for_a_famous_video_about_python/"
            },
            "content": "<p>Looking for a famous video about Python</p><p>There\u2019s this well-known video about the \"Pythonic way.\" In it, a famous python expert gives a speach on conference. He shares how he was hired by a large company to revise a Python wrapper built on top of Java libraries. At one point, he shows a sample of code to the audience and asks if they think it\u2019s Python code. They all agree that it is, but then he reveals that it\u2019s actually Java code. And yes that python is ugly and just look like java. He then goes on to explain how he transforms it into a more Pythonic approach, adding methods for `with` and `for`, among other changes. And he completely transform code so it's python.\n\nThis video is a great language agnostic example,, and I need it for a presentation where I plan to convince people that a some go project is essentially just Java Spring, but rewritten in Go. If anyone knows this video, please share it!</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iqvcec/looking_for_a_famous_video_about_python/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iqvcec/looking_for_a_famous_video_about_python/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "40",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1im66lu/the_hidden_bias_of_alembic_and_django_migrations/"
            },
            "content": "<p>The Hidden Bias of Alembic and Django Migrations (and when to consider alternatives)</p><p>Hey all,\n\nMy name is Rotem, I'm one of the creators of [Atlas](https://atlasgo.io), a database schema-as-code tool. You can find us on [GitHub](https://github.com/ariga/atlas).\n\nI recently wrote a blog post covering cases where you might want to consider an alternative to Alembic or Django migrations for your schema changes.\n\nDon't get me wrong - alembic and Django migrations are great tools - among the best in the industry - if you are using them successfully, you should probably keep at it :-)\n\nHowever, over the years, I've come to realize that these tools, having been built to fit the use case of serving an ORM, have biases that might hinder your project.\n\nIn case you are interested, you can [find the blog post here](https://atlasgo.io/blog/2025/02/10/the-hidden-bias-alembic-django-migrations?utm_source=reddit&utm_medium=post&utm_campaign=python).\n\nAtlas has two capabilities that enable it to work very well inside ORM codebases, `external_schema` and `composite_schema`. Atlas has ORM integration plugins called \"providers\" that allow it to read the desired schema of the database from your ORM code, you can then use it like:\n\n    data \"external_schema\" \"sqlalchemy\" {\n        program = [\n            \"atlas-provider-sqlalchemy\",\n            \"--path\", \"./models\",\n            \"--dialect\", \"postgresql\"\n        ]\n    }\n    \n    data \"composite_schema\" \"example\" {\n      // First, load the schema with the SQLAlchemy provider\n      schema \"public\" {\n        url = data.external_schema.sqlalchemy.url\n      }\n      // Next, load the additional schema objects from a SQL file\n      schema \"public\" {\n        url = \"file://extra_resources.sql\"\n      }\n    }\n    \n    env \"local\" {\n      src = data.composite_schema.example.url\n      // ... other configurations\n    }\n\nWhat happens here is:\n\n* Atlas reads the sqlalchemy schema from the \"models\" package and loads its SQL representation\n* Atlas calculates the composites schema from [sqlalchemy](https://github.com/ariga/atlas-provider-sqlalchemy) \\+ \"extra\\_resources.sql\"\n* Atlas uses this composite schema as the desired state for your project\n\nFrom there, similarly to alembic/django migrations atlas can automatically calculate migrations for you.\n\nIf you read all the way down here and want to learn more, the blog [post is here](https://atlasgo.io/blog/2025/02/10/the-hidden-bias-alembic-django-migrations?utm_source=reddit&utm_medium=post&utm_campaign=python) for you to read.\n\nAs always, keen to hear your feedback and answer any questions.\n\n\\-R</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1im66lu/the_hidden_bias_of_alembic_and_django_migrations/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1im66lu/the_hidden_bias_of_alembic_and_django_migrations/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "41",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1izzw4t/introducing_airdoodle_i_built_an_application_to/"
            },
            "content": "<p>Introducing AirDoodle \u2013 I built an application to make presentations with Hand Gestures! \ud83d\udc4c#python</p><p>I believe presentations should be seamless, interactive, and futuristic\u2014so I built AirDoodle to make that happen! No clickers, no keyboards\u2014just hand gestures powered by programming. \ud83d\udd90\ufe0f\n\n[https://youtu.be/vJzXBaDmKYg](https://youtu.be/vJzXBaDmKYg)</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1izzw4t/introducing_airdoodle_i_built_an_application_to/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1izzw4t/introducing_airdoodle_i_built_an_application_to/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "42",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ift077/recently_wrote_a_blog_post_about_python_without/"
            },
            "content": "<p>Recently Wrote a Blog Post About Python Without the GIL \u2013 Here\u2019s What I Found! \ud83d\ude80</p><p>Python 3.13 introduces an experimental option to disable the Global Interpreter Lock (GIL), something the community has been discussing for years.\n\nI wanted to see how much of a difference it actually makes, so I explored and ran benchmarks on CPU-intensive workloads, including:\n- Docker Setup: Creating a GIL-disabled Python environment\n- Prime Number Calculation: A pure computational task\n- Loan Risk Scoring Benchmark: A real-world financial workload using Pandas\n\n\ud83d\udd0d Key takeaways from my benchmarks:\n- Multi-threading with No-GIL can be up to 2x faster for CPU-bound tasks.\n- Single-threaded performance can be slower due to reliance on the GIL and still experimental mode of the build.\n- Some libraries still assume the GIL exists, requiring manual tweaks.\n\n\ud83d\udcd6 I wrote a full blog post with my findings and detailed benchmarks:\nhttps://simonontech.hashnode.dev/exploring-python-313-hands-on-with-the-gil-disablement\n\n\nWhat do you think? Will No-GIL Python change how we use Python for CPU-intensive and parallel tasks?\n</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ift077/recently_wrote_a_blog_post_about_python_without/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ift077/recently_wrote_a_blog_post_about_python_without/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "43",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iojoef/time_to_stop_using_filter/"
            },
            "content": "<p>Time to stop using filter()?</p><p>Python's built-in `filter()` function predates generators, and it has persisted, partly out of habit, partly for legacy reasons, and partly because it can be a bit faster than generators.\n\nHaving recently tested the performance of filters vs generators in Python 3.13, I found the speed benefit has reversed. In all of my tests, generators were faster than the equivalent filter call - typically by 5 to 10%.\n\nIs it now time to stop using `filter()` in new code (Python >= 3.13), or are there still cases where it is clearly the better option?</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iojoef/time_to_stop_using_filter/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iojoef/time_to_stop_using_filter/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "44",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ix4m99/opensource_reverse_proxy_to_remove_sensitive_data/"
            },
            "content": "<p>Open-source reverse proxy to remove sensitive data from OpenAI API calls</p><p>Hi, r/Python!\n\nI'd like to share the project I've been working on during the last few weekends.\n\n- Code: https://github.com/edublancas/sanitAI\n- Video tutorial: https://youtu.be/bdA7T6Z6YQ4\n\n**What My Project Does**\n\nSanitAI is a proxy that intercepts calls to OpenAI's API and removes sensitive data. You can add and update rules via an AI agent that asks a few questions, and then defines and tests the rule for you.\n\nFor example, you might add a rule to remove credit card numbers and phones. Then, when your users send:\n\n> Hello, my card number is 4111-1111-1111-1111. Call me at (123) 456-7890\n\nThe proxy will remove the sensitive data and send this instead:\n\n> Hello, my card number is <VISA-CARD>. Call me at <US-NUMBER>\n\n\n**Target Audience**\n\nEngineers using the OpenAI at work that want to prevent sensitive data from leaking.\n\n**Comparison**\n\nThere are several libraries to remove sensitive data from text, however, you still need to do the integration with OpenAI, this project automates adding, and maitaining the rules, and provides a transparent integration with OpenAI. No need to change your existing code.</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ix4m99/opensource_reverse_proxy_to_remove_sensitive_data/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ix4m99/opensource_reverse_proxy_to_remove_sensitive_data/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "45",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ivt2df/livedocs_a_modern_realtime_collaborative_python/"
            },
            "content": "<p>Livedocs \u2013 a modern, real-time collaborative Python notebook. Improving ergonomics for Python</p><p>Hi everyone, we (me and two other Python/Rust/Typescript devs) just built a collaborative Python notebook. We built it from the ground up, but are still using Jupyter at the core, but stripped away everything else that slows it down. Livedocs lives in your browser, and lets you experiment in a notebook and share your work as an app.\n\nOur plan is to make it the fastest, most ergonomic Python notebook around. A few things we\u2019ve shipped:\n\n* Added lots of new cell types like charts, SQL (powered by DuckDB), tables, inputs, database saves, and even interacting with LLMs directly via a cell\n* Notebook is internally represented as a DAG, for reactivity\u00a0\n* Re-built most internals with rust\n* Added support for user-supplied secrets, built-in vars\n\nWe\u2019re looking to improve the Python editing experience by connecting the editor to an LSP and adding AI generation to help produce code.\u00a0\n\nWe\u2019re looking for feedback on the notebook from Pythonistas on the ergonomics of the notebook. We want to keep the experience as close to a local development environment as possible.\u00a0</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ivt2df/livedocs_a_modern_realtime_collaborative_python/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ivt2df/livedocs_a_modern_realtime_collaborative_python/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "46",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1irl4ap/efficient_python_programming_a_guide_to_threads/"
            },
            "content": "<p>Efficient Python Programming: A Guide to Threads and Multiprocessing</p><p>\ud83d\ude80 Want to speed up your Python code? This video dives into **threads vs. multiprocessing**, explaining when to use each for maximum efficiency. Learn how to handle **CPU-bound** and **I/O-bound** tasks, avoid common pitfalls like the GIL, and boost performance with parallelism. Whether you're optimizing scripts or building scalable apps, this guide has you covered!\n\n\ud83d\udd17 Watch here: [https://www.youtube.com/watch?v=BfwQs1sEW7I&t=485s](https://www.youtube.com/watch?v=BfwQs1sEW7I&t=485s)\n\n\ud83d\udcac Got questions or tips? Drop them in the comments!</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1irl4ap/efficient_python_programming_a_guide_to_threads/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1irl4ap/efficient_python_programming_a_guide_to_threads/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "47",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iscyp4/a_drum_machine_and_16step_sequencer/"
            },
            "content": "<p>A drum machine and 16-step sequencer</p><p># Background\n\nI am posting a series of Python scripts that demonstrate using Supriya, a Python API for SuperCollider, in a dedicated subreddit. Supriya makes it possible to create synthesizers, sequencers, drum machines, and music, of course, using Python.\n\nAll demos are posted here:\u00a0[r/supriya\\_python](https://www.reddit.com/r/supriya_python/).\n\nThe code for all demos can be found in this GitHub\u00a0[repo](https://github.com/dayunbao/supriya_demos).\n\nThese demos assume knowledge of the Python programming language. They do not teach how to program in Python. Therefore, an intermediate level of experience with Python is required.\n\n# The demo\n\nIn the [latest](https://www.reddit.com/r/supriya_python/comments/1iscpf1/a_drum_machine_and_16step_sequencer/) demo, I show how to create a drum machine with a 16-step sequencer.  Much of the post is dedicated to discussing the various design-related decisions that must be made when creating a step sequencer.  Please give the demo script a try and let me know what you think.</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iscyp4/a_drum_machine_and_16step_sequencer/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iscyp4/a_drum_machine_and_16step_sequencer/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "48",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1inhere/getting_told_plsql_is_a_better_option_compare_to/"
            },
            "content": "<p>Getting told \u201cPL/SQL is a better option compare to Python\u201d on Report Automation</p><p>Background: Recently I\u2019m working on a report automation task using Python Pandas library, but - I was told by the TI team (Tech infra) that currently they are having issues with the Pandas library on the servers, so I\u2019m asked to find alternatives to revise my finished program\u2026\n\nThe problem is while I\u2019m looking for alternatives, I\u2019m getting a lot of options or ideas from not just my own team, but other teams. \n\nAnd one of the Senior employees on my team asked me what my Python program is doing, after I explained my program logic, he basically told me \u201cYou shouldn\u2019t use Python for this task in the first place. Should just use PL SQL\u201d Because:\n1. PL SQL is being used by my team for a long time, most of people are more familiar with it.\n2. Using PL SQL avoids the Python Libraries issue\n3. It\u2019s approved by the company so no need to worry about \u201cgetting approvals\u201d\n\nMaybe this option could work and he is trying to help, but I\u2019m not convinced by his explanations on why PL SQL is a better option specifically in the context of the report automation task which requires:\n1. Iterating through each rows of data, uses a set of logic to do:\nTable formatting,\nData conditional formatting\n\n2. Consolidate all data and other pieces into a HTML file and send through an email \n3. I was already using Python, if I switch over to PL SQL, that\u2019s not \u201crevising\u201d anymore, that is restart from scratch again - Why would anyone want that?\n\nAt the same time I don\u2019t think \u201cPython is a bad option to start with in the first place\u201d, am I overthinking?</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1inhere/getting_told_plsql_is_a_better_option_compare_to/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1inhere/getting_told_plsql_is_a_better_option_compare_to/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "49",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1inj8if/parscrape_v051_released/"
            },
            "content": "<p>ParScrape v0.5.1 Released</p><p># What My project Does:\n\nScrapes data from sites and uses AI to extract structured data from it.\n\n# Whats New:\n\n* BREAKING CHANGE: --ai-provider Google renamed to Gemini.\n* Now supports XAI, Deepseek, OpenRouter, LiteLLM\n* Now has much better pricing data.\n\n# Key Features:\n\n* Uses Playwright / Selenium to bypass most simple bot checks.\n* Uses AI to extract data from a page and save it various formats such as CSV, XLSX, JSON, Markdown.\n* Has rich console output to display data right in your terminal.\n\n# GitHub and PyPI\n\n* PAR Scrape is under active development and getting new features all the time.\n* Check out the project on GitHub or for full documentation, installation instructions, and to contribute:\u00a0[https://github.com/paulrobello/par\\_scrape](https://github.com/paulrobello/par_scrape)\n* PyPI [https://pypi.org/project/par\\_scrape/](https://pypi.org/project/par_scrape/)\n\n# Comparison:\n\nI have seem many command line and web applications for scraping but none that are as simple, flexible and fast as ParScrape\n\n# Target Audience\n\nAI enthusiasts and data hungry hobbyist</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1inj8if/parscrape_v051_released/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1inj8if/parscrape_v051_released/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "50",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iw96ed/the_pitfalls_of_benchmarking_your_package_like/"
            },
            "content": "<p>The pitfalls of benchmarking your package like numpy does</p><p>Recently I decided to use [asv (Airspeed Velocity)](https://asv.readthedocs.io/en/latest/) for benchmarking performance of [django-components](https://django-components.github.io/django-components) (we want to be faster than Django templates). asv is used by numpy, scipy, or astropy.\n\nWith asv, we are able benchmark render time and memory consumption.\n\nThere was a lot of pitfalls and even a couple of bugs I had to fix to get things working. I've documented them all in [this PR](https://github.com/django-components/django-components/pull/999) (also contains screenshots).\n\nThe PR covers these use cases:\n\n* Performance report on pull requests.\n* Benchmarking the package across releases.\n* Displaying performance results on a website.\n\nI'm not big on writing blogs and tutorials (at least not by myself), so I hope to share resources at least this way. The PR is still very informative if you want to introduce benchmarking to your project.\n\nIf you find this useful and you'd want to make this into a more human-digestible format, send me a message!</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iw96ed/the_pitfalls_of_benchmarking_your_package_like/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iw96ed/the_pitfalls_of_benchmarking_your_package_like/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "51",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ii1i6z/how_frequently_do_you_use_parallel_processing_at/"
            },
            "content": "<p>How frequently do you use parallel processing at work?</p><p>Hi guys! I'm curious about your experiences with parallel processing. How often do you use it in your at work. I'd live to hear your insights and use cases</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ii1i6z/how_frequently_do_you_use_parallel_processing_at/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ii1i6z/how_frequently_do_you_use_parallel_processing_at/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "52",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iyv3vp/how_much_of_fluent_python_is_outdated_with_the/"
            },
            "content": "<p>How much of Fluent Python is outdated with the release of Python 3.13</p><p>I am currently working through Fluent Python 2nd edition. Should I skip certain sections since Python 3.13 (free-threading) is released? If so, which ones?</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iyv3vp/how_much_of_fluent_python_is_outdated_with_the/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iyv3vp/how_much_of_fluent_python_is_outdated_with_the/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "53",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ik0tw7/best_way_to_get_better_at_practical_python_coding/"
            },
            "content": "<p>Best way to get better at practical Python coding</p><p>I've noticed a trend in recent technical interviews - many are shifting towards project-based assessments where candidates need to build a mini working solution within 45 minutes.\n\nWhile we have LeetCode for practicing algorithm problems, what's the best resource for practicing these types of practical coding challenges? Looking for platforms or resources that focus on building small, working applications under time pressure.\n\nAny recommendation is much appreciated!\n\n(Update: removed the website mentioned, not associated with it at all :) )</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ik0tw7/best_way_to_get_better_at_practical_python_coding/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ik0tw7/best_way_to_get_better_at_practical_python_coding/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "54",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ivclq9/tinyprogress_101_released/"
            },
            "content": "<p>Tinyprogress 1.0.1 released</p><p># What My Project Does:\n\nIt is a lightweight console progress bar that weighs only 1.21KB.\n\n# What Problem Does It Solve?\n\nIt aims to reduce the dependency size in certain programs.\n\n# Comparison with Other Available Modules for This Function:\n\n* **progress** \\- 8.4KB\n* **progressbar** \\- 21.88KB\n* **tinyprogress** \\- 1.21KB\n\n# GitHub and PyPI:\n\nCheck out the project on GitHub for full documentation:  \n[https://github.com/croketillo/tinyprogress](https://github.com/croketillo/tinyprogress)\n\nAvailable on PyPI:  \n[https://pypi.org/project/tinyprogress/](https://pypi.org/project/tinyprogress/)\n\n# Target Audience:\n\nPython developers looking for lightweight dependencies.</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ivclq9/tinyprogress_101_released/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ivclq9/tinyprogress_101_released/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "55",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1itzsnz/my_everexpanding_python_django_notes/"
            },
            "content": "<p>My Ever-Expanding Python & Django Notes</p><p>Hey everyone! \ud83d\udc4b\n\nI wanted to share a project I've been working on: [**Code-Memo**](https://mouhamaddev.github.io/Code-Memo/) \u2013 a personal collection of coding notes. This is NOT a structured learning resource or a tutorial site but more of a **living reference** where I document everything I know (and continue to learn) about Python, Django, Linux, AWS, and more.\n\nSome pages:  \n\ud83d\udccc [**Python Notes**](http://mouhamaddev.github.io/Code-Memo/python.html)  \n\ud83d\udccc [**Django Notes**](http://mouhamaddev.github.io/Code-Memo/django.html)\n\nThe goal is simple: **collect knowledge, organize it, and keep expanding.** It will never be \"finished\" because I\u2019m always adding new things as I go. If you're a Python/Django developer, you might find something useful in there\u2014or even better, you might have suggestions for things to add!\n\nWould love to hear your thoughts.</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1itzsnz/my_everexpanding_python_django_notes/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1itzsnz/my_everexpanding_python_django_notes/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "56",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ijc5gm/i_made_a_doublependulum_physics_simulation_using/"
            },
            "content": "<p>I made a double-pendulum physics simulation using the pygame library! Open-source.</p><p># What is it?\n\nThis is a project I've been working on for fun. It simulates the double pendulum, it uses the Lagrangian equations of motion and RK4 numerical integration for the physics. You can adjust parameters and initial conditions freely\n\n# Comparison to alternatives\n\nI haven't found much projects like this, but I thought this looked quite clean, and alternatives used libraries like matplotlib and jupyter notebook, while this one uses pygame\n\n# Target audience\n\nJust for people who like physics simulations or are curious on implementing more functionality or work on similar projects.\n\nHave fun! Here's the github repo:\n\nhttps://github.com/Flash09a14/Double-Pendulum-Simulation</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ijc5gm/i_made_a_doublependulum_physics_simulation_using/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ijc5gm/i_made_a_doublependulum_physics_simulation_using/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "57",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1io2ohv/segment_anything_ui_segmentation_object_detection/"
            },
            "content": "<p>Segment anything UI: Segmentation / object detection annotation made the easy way</p><p>Hello to everyone.\n\nI have officially released segment anything ui for **segmentation / object detection** annotation tasks. It is a PySide6 application.  \n\n\nI have been working on this tool for some time and I hope that it will help to remove annoying instance segmentation / object detection annotation. It is designed to be simple, feature rich and as automatic as possible. Feel free to request features, bugfixes or star the project. \n\n  \n[https://github.com/branislavhesko/segment-anything-ui](https://github.com/branislavhesko/segment-anything-ui)\n\n  \nLet's do the annotations the most pleasant way.</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1io2ohv/segment_anything_ui_segmentation_object_detection/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1io2ohv/segment_anything_ui_segmentation_object_detection/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "58",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iyhjax/kreuzberg_next_steps/"
            },
            "content": "<p>Kreuzberg: Next Steps</p><p>Hi Peeps,\n\nI'm the author of [kreuzberg](https://github.com/Goldziher/kreuzberg) - a text extraction library named after the beautiful neighborhood of Berlin I call home. \n\nI want your suggestions on the next major version of the library - what you'd like to see there and why. I'm asking here because I'd like input from many potential or actual users.\n\nTo ground the discussion - the main question is, what are your text extraction needs? What do you use now, and where would you consider using Kreuzberg? \n\nThe differences between Kreuzberg and other OSS Python libraries with similar capabilities (unstructured.io, docking, markitdown) are these:\n\n- much smaller size, making Kreuzberg ideal for serverless and dockerized applications \n- CPU emphasis \n- no API round trips (actual of the others as well in some circumstances)\n\nI will keep Kreuzberg small - this is integral for my use cases, dockerized rag micro services deployed on cloud run (scaling to 0). \n\nBut I'm considering adding `extra` dependency groups to support model-based (think open-source vision models) text extraction with or without GPU acceleration. \n\nThere is also the question about layout extraction and PDF metadata. I'd really be interested in hearing whether you guys have use for these and how you actually use them. Why? These can be useful, but usually in an ML/data science context, and I'd assume if you already are proficient with DS technologies, you might be doing this on your own. \n\nAlso, what formats are currently missing that I should strive to support? I know voice transcription, etc., and video, but I am skeptical about adding these to Kreuzberg. I don't see these as being in the same problem domain exactly, and I'm not sure what can be done without proper GPU here, either. \n\nAny insights or suggestions are welcome.\n\nAlso, feel free to open issues with suggestions or discussions in the repo. \n\nP.S. I'm foreseeing criticism calling this post an \"ad\" or something like that. I won't deny that I'd like to create awareness and discourse around the library, but this is not my intention in this post. I want to discuss this and get the insights; this is my best bet. </p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iyhjax/kreuzberg_next_steps/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iyhjax/kreuzberg_next_steps/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "59",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ij8utg/creating_music_with_python/"
            },
            "content": "<p>Creating music with Python</p><p>I created a new reddit community dedicated to\u00a0[Supriya](https://github.com/supriya-project/supriya), the Python API for SuperCollider. It's here\u00a0[r/supriya\\_python](https://www.reddit.com/r/supriya_python/). If anyone is interested in creating music/sound with the Python programming language, please come and check it out. If you aren't familiar with SuperCollider, it's described as \"a platform for audio synthesis and algorithmic composition, used by musicians, artists and researchers working with sound.\" You can check out the website\u00a0[here](https://supercollider.github.io/). Supriya allows you to use the Python programming language to interact with SuperCollider's server, which offers wavetable synthesis, granular synthesis, FM synthesis, sampling (both recording, playback, and manipulation), effects, and a lot more. It's really cool.\n\n  \nIn the coming days I'll be adding code to show how to use Supriya to generate sounds, handle MIDI, route audio signals through effects, and more.</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ij8utg/creating_music_with_python/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ij8utg/creating_music_with_python/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "60",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ign06a/found_this_cool_python_wfp_library_that_makes/"
            },
            "content": "<p>Found this cool Python WFP library that makes network filtering super easy in Windows!</p><p>Found this cool Python WFP library that makes network filtering super easy\n\nJust discovered PyWFP while looking for a way to handle Windows Filtering Platform in Python. It's pretty neat - lets you create network filters with really simple syntax, similar to Windivert if anyone's familiar with that.\n\nQuick example of what you can do:\n\n```python\nfrom pywfp import PyWFP\npywfp = PyWFP()\nfilter_string = \"outbound and tcp and remoteaddr == 192.168.1.3 and tcp.dstport == 8123\"\n\nwith pywfp.session():\n    pywfp.add_filter(filter_string, filter_name=\"My Filter\")\n```\nThe syntax is really straightforward - you can filter by:\n\n\\* TCP/UDP/ICMP\n\n\\* IP ranges\n\n\\* Specific ports\n\n\\* Inbound/outbound traffic\n\nBeen playing with it for a bit and it works great if you need to programmatically manage Windows network filters. Thought others might find it useful!\n\nLink: [Github](https://github.com/adrianpitigoi/pywfp)</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ign06a/found_this_cool_python_wfp_library_that_makes/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ign06a/found_this_cool_python_wfp_library_that_makes/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "61",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1igtrtp/htmltomarkdown_12_modern_html_to_markdown/"
            },
            "content": "<p>\ud83d\ude80 html-to-markdown 1.2: Modern HTML to Markdown Converter for Python</p><p>Hi Pythnoista's!\n\nI'm excited to share with you [html-to-markdown](https://github.com/Goldziher/html-to-markdown).\n\nThis library started as a fork of [markdownify](https://pypi.org/project/markdownify/) - I used it when I wrote a webscaper and was frustrated with its lack of typing. I started off by adding a `py.typed` file, but found myself rewriting the entire library to add typing and more extensive tests, switching from its class based approach to a lighter, functional codebase.\n\n## Target Audience\n\n- Python developers working with HTML content conversion.\n- Web scrapers needing clean Markdown output.\n- Documentation tooling maintainers.\n- Anyone migrating content from HTML to Markdown-based systems.\n\n## Alternatives & Origins\n\nThis library is a fork of [markdownify](https://pypi.org/project/markdownify/), an excellent HTML to Markdown converter that laid the groundwork for this project. While markdownify remains a solid choice, this fork takes a different approach:\n\n**html-to-markdown vs markdownify:**\n\n- Full type safety with MyPy strict mode\n- Functional API vs class-based architecture\n- Modern Python 3.9+ support\n- Strict semver versioning\n- More extensive test coverage including integration tests\n- Allows configuration of BeautifulSoup\n\n**Other alternatives:**\n\n- html2text: Popular but last updated 2020.\n- tomark: Minimal features, no typing support.\n- md-convert: Limited configuration options.\n- Beautiful Soup's get_text(): Basic text extraction only.\n\n## Quick Example\n\n```python\nfrom html_to_markdown import convert_to_markdown\n\nmarkdown = convert_to_markdown('<b>Hello</b> <a href=\"https://reddit.com\">Reddit</a>')\n# Output: '**Hello** [Reddit](https://reddit.com)'\n```\n\n## Installation\n\n```python\npip install html-to-markdown\n```\n\nCheck out the [GitHub repository](https://github.com/Goldziher/html-to-markdown) for more details and examples. If you find this useful, a \u2b50 would be greatly appreciated!\n\nThe library is MIT-licensed and open to contributions. Let me know if you have any questions or feedback!</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1igtrtp/htmltomarkdown_12_modern_html_to_markdown/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1igtrtp/htmltomarkdown_12_modern_html_to_markdown/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "62",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iy0i35/codegen_manipulate_codebases_with_python/"
            },
            "content": "<p>Codegen - Manipulate Codebases with Python</p><p>Hey folks, excited to introduce [Codegen](https://github.com/codegen-sh/codegen-sdk), a library for programmatically manipulating codbases.\n\n**What my Project Does**\n\nThink \"better LibCST\".\n\nCodegen parses the entire codebase \"graph\", including references/imports/etc., and exposes high-level APIs for common refactoring operations.\n\nConsider the following code:\n\n    from codegen import Codebase\n    \n    # Codegen builds a complete graph connecting\n    # functions, classes, imports and their relationships\n    codebase = Codebase(\"./\")\n    \n    # Work with code without dealing with syntax trees or parsing\n    for function in codebase.functions:\n        # Comprehensive static analysis for references, dependencies, etc.\n        if not function.usages:\n            # Auto-handles references and imports to maintain correctness\n            function.remove()\n    \n    # Fast, in-memory code index\n    codebase.commit()\n\nGet started:\n\n    uv tool install codegen\n    codegen notebook --demo\n\nLearn more at [docs.codegen.com](https://docs.codegen.com)!\n\n**Target Audience**\n\nCodegen scales to multimillion-line codebases (Python/JS/TS/React codebases supported) and is used by teams at Ramp, Notion, Mixpanel, Asana and more.\n\n**Comparison**\n\nOther tools for codebase manipulation include Python's AST module, LibCST, and ts-morph/jscodeshift for Javascript. Each of these focuses on a single language and for the most part focuses on AST-level changes.\n\nCodegen provides higher-level APIs targeting common refactoring operations (no need to learn specialized syntax for modifying the AST) and enables many \"safe\" operations that span beyond a single file - for example, renaming a function will correctly handle renaming all of it's callsites across a codebase, updating imports, and more.</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iy0i35/codegen_manipulate_codebases_with_python/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iy0i35/codegen_manipulate_codebases_with_python/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "63",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ioh2jq/a_polyphonic_midi_synth_in_less_than_100_lines_of/"
            },
            "content": "<p>A polyphonic MIDI synth in less than 100 lines of code</p><p># Background\n\nI am posting a series of Python scripts that demonstrate using Supriya, a Python API for SuperCollider, in a dedicated subreddit.  Supriya makes it possible to create synthesizers, sequencers, drum machines, and music, of course, using Python.\n\nAll demos are posted here: r/supriya_python.\n\nThe code for all demos can be found in this GitHub [repo](https://github.com/dayunbao/supriya_demos).\n\nThese demos assume knowledge of the Python programming language.  They do not teach how to program in Python.  Therefore, an intermediate level of experience with Python is required.\n\n# The demo\n\nIn [this](https://www.reddit.com/r/supriya_python/comments/1iog3oz/a_polyphonic_midi_synth_in_less_than_100_lines_of/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button) demo, I show how to handle MIDI messages to play a polyphonic synthesizer using Supriya.  It took a little less than 100 lines of code, which is pretty amazing.</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ioh2jq/a_polyphonic_midi_synth_in_less_than_100_lines_of/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ioh2jq/a_polyphonic_midi_synth_in_less_than_100_lines_of/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "64",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1izky8q/what_happened_to_python_weekly_newsletter/"
            },
            "content": "<p>What happened to Python Weekly newsletter?</p><p>I used to love Python weekly newsletter, but a few months (?) ago it changed dramatically.\n\nNow it has ads (!), referrals, I apparently have an \"account\" at something called \"beehive\". There's X, Facebook and Linkedin social icons, which I can only assume are tracking delivery...\n\nDisappointed. Although the core content seems unchanged, I'm unsubscribing. What happened?</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1izky8q/what_happened_to_python_weekly_newsletter/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1izky8q/what_happened_to_python_weekly_newsletter/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "65",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iggbcu/text_to_video_model_implementation_step_by_step/"
            },
            "content": "<p>Text to Video Model Implementation Step by Step</p><p># What My Project Does\n\nI've been working on a **text-to-video model** from scratch using PyTorch and wanted to share it with the community! This project is designed for those interested in **diffusion models**.\n\n# Target audience\n\nFor **students and researchers** exploring generative AI.\n\n# Comparison\n\nWhile not aiming for state of the art results, this serves as a great way to understand the fundamentals of text-to-video models.\n\n# GitHub\n\nCode, documentation, and example can all be found on GitHub: \n\n[https://github.com/FareedKhan-dev/text2video-from-scratch](https://github.com/FareedKhan-dev/text2video-from-scratch)</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iggbcu/text_to_video_model_implementation_step_by_step/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iggbcu/text_to_video_model_implementation_step_by_step/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "66",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iqsb0k/redcoffee_a_personal_pypi_project_that_crossed_6k/"
            },
            "content": "<p>RedCoffee: A Personal PyPi Project That Crossed 6K+ Downloads</p><p>Hi everyone,  \nI hope you are doing well.\n\nI just wanted to take a moment to say thank you to everyone in this community. When I first built\u00a0[RedCoffee](https://pypi.org/project/redcoffee/), it was just a hobby project\u2014something that solved a personal need. I never imagined it would cross 6,000 downloads or that so many of you would find it useful. Seeing the response, the feedback, and the feature requests has been incredibly motivating, and I truly appreciate all the support.\n\n# What my project does ?\n\nJust a quick recap - RedCoffee is a CLI tool that generates PDF reports from SonarQube Community Edition\u2019s code analysis, which lacks a native PDF export feature. While some GitHub projects addressed this need, they are no longer actively maintained. This was my pain point while working with my fellow developers and hence I built this solution.\n\nWith that, I\u2019ve just pushed v1.8, which includes a few important fixes:\n\n* Fixed: Duplication % was always showing as 0\u2014this has now been corrected.\n* Resolved: The last issue from the API response wasn\u2019t appearing\u2014this is now fixed.\n* UI Tweaks: Minor improvements to the PDF formatting.\n\n# Lessons Learned & What\u2019s Next\n\nWhile building this, I made some classic mistakes\u2014ones that I often advise others to avoid:\n\n1. Not Enough Test Coverage : I focused too much on quick iterations and didn\u2019t invest enough in unit/integration tests. As someone who strongly believes in test automation, this was something I should have done from the start. Fixing this is my top priority for the next update.\n2. Code Structure : Needs Work Right now, app . py has way too much logic packed into it. Without proper tests, refactoring is tricky. So, once I have good test coverage, cleaning up the structure is next on my list.\n\n# Upgrade to v1.8\n\nIf you\u2019re using RedCoffee, I recommend upgrading to the latest version. v1.1 is still the LTS release, but v1.8 is the most up-to-date and stable.  \nIf you are already using RedCoffee, here is the command to upgrade it\n\n    pip install redcoffee --upgrade\n\nIf you are installing RedCoffee for the first time, here is the command to get up and running\n\n    pip install redcoffee==1.8\n\n# Target Audience:\n\nRedCoffee is particularly useful for:\n\n* Small teams and startups using SonarQube Community Edition hosted on a single machine.\n* Developers and testers who need to share SonarQube reports but lack built-in options.\n* Anyone learning Click \u2013 the Python library used to build CLI applications.\n* Engineers looking to explore SonarQube API integrations.\n\n# A humble request\n\nIf you find the tool useful, I\u2019d really appreciate it if you could check out the GitHub repo and leave a star\u2014it helps independent projects like this stay visible.\n\n# Relevant Links\n\ni)\u00a0[RedCoffee - Github Repository](https://github.com/Anubhav9/RedCoffee)  \nii)\u00a0[RedCoffee - PyPi](https://pypi.org/project/redcoffee/)</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iqsb0k/redcoffee_a_personal_pypi_project_that_crossed_6k/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iqsb0k/redcoffee_a_personal_pypi_project_that_crossed_6k/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "67",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1imhrqa/inherit_from_dict_or_userdict/"
            },
            "content": "<p>Inherit from \"dict\" or \"UserDict\"?</p><p>I'm working on a project where we need to integrate a dictionary with a ttk.Treeview. The easiest approach would have been to handle data and visualization separately, but due to project requirements, we opted for a combined structure where both are tightly linked.\n\nThe idea is straightforward in theory: any change to the dictionary should be reflected in the Treeview, and any modification in the Treeview should update the dictionary. To achieve this, we're implementing the most efficient communication path between the data structure and its visualization within a single class.\n\nOur initial plan was to intercept accesses using \\_\\_getitem\\_\\_, \\_\\_setitem\\_\\_, and \\_\\_delitem\\_\\_ by inheriting directly from \"dict\". However, a teammate suggested we should use \"UserDict\" from \"collections\" instead. We did a quick switch with the little code we have so far, and in practice, both approaches seem to work exactly the same.\n\nThat said, how can we be sure which one is the better choice for extending dictionary functionality?\n\nThis has sparked some minor disagreements in our team. ChatGPT leans towards \"UserDict\", but some of us prefer minimizing intermediaries to ensure efficiency stays \"bare-metal,\" if you know what I mean.</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1imhrqa/inherit_from_dict_or_userdict/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1imhrqa/inherit_from_dict_or_userdict/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "68",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1itbo0s/pystructtype_020_automagically_create_python/"
            },
            "content": "<p>PyStructType 0.2.0 - Auto-magically create python classes to interface with c structs!</p><p>GitHub: [https://github.com/fchorney/pystructtype](https://github.com/fchorney/pystructtype)\n\n**What My Project Does**\n\nPyStructType is a package that nobody asked for (except me) that will let you leverage the Typing system to define C Structs in python as a \"StructDataclass\" and have it auto-magically create the struct encode/decode format.\n\nThe encode/decode functions are able to be extended to do all sorts of fun stuff that allows you to store the data in other ways than just ints, or lists, etc.\n\nThis system is also composable, such that you can nest StructDataclasses within others, to create more complex structs.\n\n**Target Audience**\n\nThis package is mostly just targeted towards people that need to decode/encode structs for either C-struct interfaces, or dealing with any sort of structured data such as when working with embedded hardware.\n\n**Comparison**\n\nAs  far as I'm aware, there are quite a few packaged out there that let you straight up copy and paste c-structs as strings and will convert them to classes for you, and other similar projects. \n\nThat being said, I mostly wanted to see what I could get away with, by doing weird things with the typing system.\n\n**Background**\n\nWhile other similar libraries exist, this fulfills some usefulness that I was looking for, for another project of mine, which is porting a C SDK into Python that interfaces with hardware, and I wanted an easy way to just port over the defined C structs into python and have something just do all the work for me.\n\nI can't really say that I'm an expert in type meta-programming, and how that all works, but this was a fun project at least, and I'll most likely be using it in my other project mentioned above going forward.\n\nThere is quite a bit that I'd still like to add, and unfortunately I wasn't able to make the custom \"types\" as nice as I was hoping for, but it works (tm).\n\nI have some examples in the README, as well in a python file in the repo.\n\nIf anyone has any questions, comments, wants to tell me this already exists, or that I'm using typing really incorrectly, then please have at it!</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1itbo0s/pystructtype_020_automagically_create_python/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1itbo0s/pystructtype_020_automagically_create_python/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "69",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ind8kn/preswald_a_fullstack_python_sdk_for_building_and/"
            },
            "content": "<p>Preswald: A full-stack Python SDK for building and deploying interactive data apps</p><p>Hi everyone,\n\n[Preswald](https://github.com/StructuredLabs/preswald) is a lightweight, full-stack SDK that helps you build, deploy, and manage interactive data applications. all with minimal Python and SQL. It brings together data ingestion, storage, transformation, and visualization into one simple framework.\n\n**Source Code:** [https://github.com/StructuredLabs/preswald](https://github.com/StructuredLabs/preswald)\n\n**Slack:** [Community](https://structured-users.slack.com/join/shared_invite/zt-265ong01f-UHP6BP3FzvOmMQDIKty_JQ)\n\n  \n**Features:Target Audience / Why Use It:**\n\n* Build apps with minimal Python/SQL.\n* Handle ingestion, ETL, and visualization in one SDK.\n* Connect to CSV, JSON, Parquet, or SQL databases easily.\n* Customize your app\u2019s look with simple tweaks in `preswald.toml`.\n* Deploy locally or to Google Cloud Run with one command.\n* Lightweight and simple, no need for a huge data stack.\n\nIf you\u2019re tired of juggling tools to get simple data apps up and running, this might make life easier. It\u2019s good for quick internal tools, dashboards, or just experimenting with data.</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ind8kn/preswald_a_fullstack_python_sdk_for_building_and/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ind8kn/preswald_a_fullstack_python_sdk_for_building_and/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "70",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ij1fk7/semanticchunker_v020_typesafe_structurepreserving/"
            },
            "content": "<p>semantic-chunker v0.2.0: Type-Safe, Structure-Preserving Semantic Chunking</p><p>Hey Pythonistas! Excited to announce v0.2.0 of [semantic-chunker](https://github.com/Goldziher/semantic-chunker), a **strongly-typed, structure-preserving text chunking library** for intelligent text processing. Whether you're working with LLMs, documentation, or code analysis, **semantic-chunker** ensures your content remains meaningful while being efficiently tokenized.  \n\nBuilt on top of **semantic-text-splitter (Rust-based core)** and integrating **tree-sitter-language-pack** for syntax-aware code splitting, this release brings **modular installations** and **enhanced type safety**.\n\n## \ud83d\ude80 What's New in v0.2.0?\n\n- **\ud83d\udce6 Modular Installation**: Install only what you need  \n  \n  ```bash\n  pip install semantic-chunker          # Text & markdown chunking  \n  pip install semantic-chunker[code]    # + Code chunking  \n  pip install semantic-chunker[tokenizers]  # + Hugging Face support  \n  pip install semantic-chunker[all]     # Everything  \n  ```\n\n- **\ud83d\udcaa Improved Type Safety**: Enhanced typing with **Protocol types**\n- **\ud83d\udd04 Configurable Chunk Overlap**: Improve context retention between chunks\n\n## \ud83c\udf1f Key Features\n\n- \ud83c\udfaf **Flexible Tokenization**: Works with OpenAI's `tiktoken`, Hugging Face tokenizers, or custom tokenization callbacks  \n- \ud83d\udcdd **Smart Chunking Modes**:\n  - **Plain text**: General-purpose chunking  \n  - **Markdown**: Preserves structure  \n  - **Code**: Syntax-aware chunking using **tree-sitter**\n- \ud83d\udd04 **Configurable Overlapping**: Fine-tune chunking for better context  \n- \u2702\ufe0f **Whitespace Trimming**: Keep or remove whitespace based on your needs  \n- \ud83d\ude80 **Built for Performance**: Rust-powered core for high-speed chunking  \n\n## \ud83d\udd25 Quick Example\n\n```python\nfrom semantic_chunker import get_chunker\n\n# Markdown chunking\nchunker = get_chunker(\n    \"gpt-4o\",\n    chunking_type=\"markdown\",\n    max_tokens=10,\n    overlap=5\n)\n\n# Get chunks with original indices\nchunks = chunker.chunk_with_indices(\"# Heading\\n\\nSome text...\")\nprint(chunks)\n```\n\n## Target Audience\n\nThis library is for anyone who needs semantic chunking-\n\n- **AI Engineers**: Optimizing input for context windows while preserving structure  \n- **Data Scientists & NLP Practitioners**: Preparing structured text data  \n- **API & Backend Developers**: Efficiently handling large text inputs\n\n## Alternatives\n\nNon-exhaustive list of alternatives:\n\n- **\ud83c\udd9a `langchain.text_splitter`** \u2013 More features, heavier footprint. Use **semantic-chunker** for better performance and minimal dependencies.  \n- **\ud83c\udd9a `tiktoken`** \u2013 OpenAI\u2019s tokenizer splits text but lacks **structure preservation** (Markdown/code).  \n- **\ud83c\udd9a `transformers.PreTrainedTokenizer`** \u2013 Great for tokenization, but **not optimized for chunking with structure awareness**.  \n- **\ud83c\udd9a Custom regex/split scripts** \u2013 Often used but lacks **proper token counting, structure preservation, and configurability**.  \n\n---\n\nCheck out [the GitHub repository](https://github.com/Goldziher/semantic-chunker) for more details and examples. If you find this useful, a \u2b50 would be greatly appreciated!\n\nThe library is MIT-licensed and open to contributions. Let me know if you have any questions or feedback!</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ij1fk7/semanticchunker_v020_typesafe_structurepreserving/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ij1fk7/semanticchunker_v020_typesafe_structurepreserving/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "71",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ipfgme/docullim_aipowered_python_documentation/"
            },
            "content": "<p>Docullim:  AI-Powered Python Documentation</p><p>Hey r/Python ! I just released [docullim](https://github.com/shrynx/docullim), a Python library that helps auto-generate documentation using LLMs\u2014but with a twist. Instead of processing your entire codebase, docullim lets you selectively document functions and classes by adding a simple @`docullim` annotation.\n\n# What My Project Does\n\n* Add   @`docullim` any function or class, and it generates documentation for just that part of your code.\n* Supports custom tags: @`docullim`(\"custom\\_tag\") lets you customise prompts.\n* Flexible CLI: Process individual files, directories, or even glob patterns like docullim \"src/\\*\\*/\\*.py\".\n* Outputs structured JSON so you can use it however you want.\n* Caches results locally to avoid redundant API calls and speed up future runs.\n* Works with custom models & configs: docullim --config docullim.json --model gpt-4 \"src/\\*\\*/\\*.py\"\n* It supports multiple different LLMs\n\n# Target Audience\n\n* **Developers & teams** who want AI-generated documentation **without bloating their entire repo**.\n* **Maintainers of large projects** who need a structured, incremental approach to documentation.\n* **Tooling enthusiasts** looking for **LLM-powered doc generation** that integrates into their workflow.\n\n# Comparison\n\nUnlike other AI documentation tools, **Docullim doesn\u2019t generate docs for everything**\u2014it only runs where you tell it to. This makes it:  \n**Faster** (fewer API calls, less processing)  \n**More controllable** (no irrelevant or low-quality docstrings)  \n**Easier to integrate** (works with selective caching & structured JSON output)\n\nWould love feedback, feature requests, and contributions! Check it out here [docullim](https://github.com/shrynx/docullim)\n\n# </p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ipfgme/docullim_aipowered_python_documentation/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ipfgme/docullim_aipowered_python_documentation/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "72",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iy9q5f/built_an_orm_a_minimal_asynchronous_orm_for/"
            },
            "content": "<p>Built an ORM: A Minimal Asynchronous ORM for Python and PostgreSQL</p><p>- What My Project Does: ORM (Object-Relation Mapping)\n- Target Audience: Production usage\n- Comparison: It demonstrate a minimal* implementation based on asyncio and type hinting achieving rich feature ORM implementation. Compared to Django, SQLAlchemy and other ORMs, it provides better developer experience in the projects applied with type-checking (e.g. Pyright) and asyncio.\n\n\\*AST statements count (SQLAlchemy: 76,228 , Peewee: 5,451, orm1: 677)\n\n[orm1](https://github.com/hanpama/orm1) is an asynchronous Object-Relational Mapping (ORM) library for Python and PostgreSQL.\n\n**Features**\n\n* Asyncio\n* Auto-mapping with Type Hints\n* DDD Aggregate Support\n* Query Builder\n* Raw SQL Queries\n* Nested Transaction Management\n* Composite Key Support\n\n**Example**\n\nInstall orm1 using pip:\n\n```sh\npip install orm1\n```\n\nDefine your database models with type hints:\n\n```python\nfrom orm1 import auto\n\n@auto.mapped()\nclass Post:\n    id: int\n    title: str\n    content: str\n    attachments: list[\"PostAttachment\"]\n\n@auto.mapped(parental_key=\"post_id\")\nclass PostAttachment:\n    id: int\n    post_id: int\n    file_name: str\n    url: str\n```\n\nPerform CRUD operations using a session:\n\n```python\n# Create a new post with an attachment.\npost = Post()\npost.title = \"Introducing orm1\"\npost.content = \"orm1 is a lightweight asynchronous ORM for Python.\"\n\nattachment = PostAttachment()\nattachment.file_name = \"diagram.png\"\nattachment.url = \"http://example.com/diagram.png\"\n\npost.attachments = [attachment]\n\n# Save the post (and cascade save the attachment as part of the aggregate).\nawait session.save(post)\n```\n\nUpdate:\n\n```python\n# Update the post's title.\npost.title = \"Introducing orm1 - A Lightweight Async ORM\"\npost.attachments[0].file_name = \"diagram_v2.png\"\npost.attachments.append(\n    PostAttachment(file_name=\"code.py\", url=\"http://example.com/code.py\")\n)\n\nawait session.save(post)\n```\n\nQueries:\n\n```python\n# Query for a post by title.\nquery = session.query(Post, alias=\"p\")\nquery = query.where('p.\"title\" = :title', title=\"Introducing orm1\")\nposts = await query.fetch()\n\n# Get a single post.\npost = await query.fetch_one()\n```\n\nThis small piece of ORM implementation has been pretty useful in many of my previous projects.\n\nYou can check more in the Github repository \ud83d\ude47: [https://github.com/hanpama/orm1](https://github.com/hanpama/orm1)\n</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iy9q5f/built_an_orm_a_minimal_asynchronous_orm_for/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iy9q5f/built_an_orm_a_minimal_asynchronous_orm_for/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "73",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iou9nx/turn_entire_youtube_playlists_to_markdown/"
            },
            "content": "<p>Turn Entire YouTube Playlists to Markdown Formatted and Refined Text Books (in any language)</p><p>Give it any YouTube playlist(entire courses for instance) and receive a clean, formatted and structured file with all the details of that playlist.\n\nIt's a simple yet effective script using the free Google Gemini API.\n\nI haven't found any free tool available with this scale, so I made one.\n\nThis Python application extracts transcripts from YouTube playlists and refines them using the Google Gemini API(which is free). It takes a YouTube playlist URL as input, extracts transcripts for each video, and then uses Gemini to reformat and improve the readability of the combined transcript. The output is saved as a text file.\n\n**What My Project Does**:\n\n* Batch processing of entire playlists\n* Refine transcripts using Google Gemini API for improved formatting and readability.\n* User-friendly PyQt5 graphical interface.\n* Selectable Gemini models.\n* Output to markdown file.\n\n**Target Audience**:\n\nTurning large YouTube playlist into one large formatted text file has many advantages for studying and learning, documentation, having a source book of the playlist, etc...\n\n  \n**Comparison**:\n\nI haven't found a similar tool that converts YouTube videos to easily readable document in this scale and be free and accessible.\n\nCheck it out : [https://github.com/Ebrizzzz/Youtube-playlist-to-formatted-text](https://github.com/Ebrizzzz/Youtube-playlist-to-formatted-text)</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iou9nx/turn_entire_youtube_playlists_to_markdown/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iou9nx/turn_entire_youtube_playlists_to_markdown/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "74",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1inlq7x/jupad_python_notepad/"
            },
            "content": "<p>jupad - Python Notepad</p><p>I've always used python as a calculator but wanted something that feels more like a soulver sketchpad.\n\n* **Source code:** [ jupad - Python Notepad](https://github.com/idanpa/jupad)\n* **Target audience:** Developer tool\n* **Comparison**: This is somewhere between python REPL to Jupyter notebook. Inspired by notepad calculators ([Soulver](https://soulver.app/),\u00a0[Numi](https://numi.app/),\u00a0[Numbr](https://numbr.dev/)), reactive jupyter notebooks ([marimo](https://github.com/marimo-team/marimo),\u00a0[ipyflow](https://github.com/ipyflow)) and similar projects ([Hydrogen](https://github.com/nteract/hydrogen)). Based on\u00a0[qtconsole](https://github.com/jupyter/qtconsole).</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1inlq7x/jupad_python_notepad/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1inlq7x/jupad_python_notepad/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "75",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1isqf8y/new_version_fastapi_guard_redis_a_fastapi/"
            },
            "content": "<p>**New version** FastAPI Guard + Redis - A FastAPI extension to secure your APIs</p><p>[Original post](https://www.reddit.com/r/Python/comments/1ilhbkk/fastapi_guard_a_fastapi_extension_to_secure_your/)\n\nI'm happy to tell you I've just released a new version (1.0.0) of FastAPI Guard - this time with Redis Integration and some other upgrades :)\n\nTake a look at the docs & repo:\n\n**Documentation**: [rennf93.github.io/fastapi-guard/](https://rennf93.github.io/fastapi-guard/)\n\n**GitHub repo**: [github.com/rennf93/fastapi-guard](https://github.com/rennf93/fastapi-guard)\n\n# Important note\n\nThe new version allows you to persist ip bans, rate limits, and more, across workers of a single application and/or other applications. Now you can have a single source of truth thanks to this integration of Redis into FastAPI Guard.\n\n**If you've already came across or read the previous post, you might want to skip the following text as it's mostly the same.**\n\n---\n\n**What is it?**\n\nFastAPI Guard is a security middleware for FastAPI that provides:\n\n- **Redis Integration** (new!)\n- IP whitelisting/blacklisting\n- Rate limiting & automatic IP banning\n- Penetration attempt detection\n- Cloud provider IP blocking\n- IP geolocation via IPInfo.io\n- Custom security logging\n- CORS configuration helpers\n\nIt's licensed under MIT and integrates seamlessly with FastAPI applications.\n\n**Comparison to alternatives**:\n- `fastapi-security`: Focuses more on authentication, while FastAPI Guard provides broader network-layer protection\n- `slowapi`: Handles rate limiting but lacks IP analysis/geolocation features\n- `fastapi-limiter`: Pure rate limiting without security features\n- `fastapi-auth`: Authentication-focused without IP management\n\n**Key differentiators**:\n- Combines multiple security layers in single middleware\n- Automatic IP banning based on suspicious activity\n- Built-in cloud provider detection\n- Daily-updated IP geolocation database\n- Production-ready configuration defaults\n\n**Target Audience**:\nFastAPI developers needing:\n- Defense-in-depth security strategy\n- IP-based access control\n- Automated threat mitigation\n- Compliance with geo-restriction requirements\n- Penetration attempt monitoring\n\n**Feedback wanted**\n\nThanks!</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1isqf8y/new_version_fastapi_guard_redis_a_fastapi/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1isqf8y/new_version_fastapi_guard_redis_a_fastapi/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "76",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iljghy/pydantic_models_for_schemaorg/"
            },
            "content": "<p>pydantic models for schema.org</p><p>[Schema.org](http://Schema.org) is\u00a0a community-driven vocabulary that allows users to add structured data to content on the web. It's used by webmasters to help search engines understand web pages. Knowledge graphs such as [yago](https://yago-knowledge.org/) also use [schema.org](http://schema.org) to enforce semantics on wikidata.\n\n* **What My Project Does** Generate pydantic models from [schema.org](http://schema.org) definition. Sample [usage](https://github.com/adsharma/schema-org-python/blob/main/tests/test_person.py).\n* **Target Audience**\u00a0People interested in knowledge graphs like Yago and wikidata\n* **Comparison** Similar things exist in the [typescript world](https://github.com/google/schema-dts), but don't seem to be maintained.\n\n  \nPotential enhancements: take schemas for other domains and generate python models for those domains. Using this and the [property graph](https://github.com/adsharma/property-graph) project, you can generate structured knowledge graphs using SQL based open source tooling.  \n</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iljghy/pydantic_models_for_schemaorg/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iljghy/pydantic_models_for_schemaorg/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "77",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iudwva/in_2025_will_there_be_a_viable_freelance_market/"
            },
            "content": "<p>In 2025 will there be a viable freelance market for Python developers other than Fiver or UpWork</p><p>Posted this question a few weeks ago but I guess it was on the wrong day.  Since it free text Friday I will try again.\n\nAre companies looking for freelance Python developers for hourly or statement of work, fixed price scripting work from places other than Upwork or Fiver or similar sites?</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iudwva/in_2025_will_there_be_a_viable_freelance_market/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iudwva/in_2025_will_there_be_a_viable_freelance_market/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "78",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1if6nk0/automation_framework_for_python/"
            },
            "content": "<p>Automation Framework for Python</p><p>What My Project Does\n\nBasically I was making a lot of automations for my clients and developed a toolset that i am using for most of my automation projects. \nIt is on Python + Playwright (for ui browser automation) + requests (covered with base modules for API automation) + DB module. I believe it maybe useful for someone of you, and I\u2019ll appreciate your stars/comments/pull-requests:\n\nhttps://github.com/eshut/Inject-Framework\n\nI understand it may be very \u00abspecialized\u00bb thing for someone, but if you need to automate something like website or api - it makes the solution structured and fast.\n\nFeel free to ask your questions.\n\nTarget Audience\n\nAnyone who is looking for software automation on Python for websites or some API\n\nComparison\n\nI believe there are similar libraries on Typescript as codecept and maybe something similar on python , but usually it is project specific </p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1if6nk0/automation_framework_for_python/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1if6nk0/automation_framework_for_python/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "79",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iyzp2m/workflow_automation_for_python_developers/"
            },
            "content": "<p>Workflow automation for Python developers</p><p>Links:\n\nGitHub (Apache-2.0 licence): [https://github.com/autokitteh/autokitteh](https://github.com/autokitteh/autokitteh)\n\nManaged platform (Free Beta): [https://app.autokitteh.cloud/](https://app.autokitteh.cloud/)\n\nWorkflows library: [https://github.com/autokitteh/kittehub](https://github.com/autokitteh/kittehub)\n\n# What My Project Does\n\nAutoKitteh is an open-source platform for connecting applications and APIs through **pure Python**\u2014letting you build, debug, and manage **reliable automations** in just a few lines of code (often with the help of AI).\n\n# Why Use It?\n\n\\- **Serverless code execution platform or Self-Hosted**  \n**- Pre-Built Connectors** \u2013 Integrate with Gmail, Slack, GitHub, ChatGPT, and more simplifying authentication (which is a pain)   \n**- Durable Execution** \u2013 If your automation stops (crash, restart, or deployment), AutoKitteh **automatically resumes** from where it left off.  \n**- Built-in Monitoring & Management** \u2013 Track and control your workflows in a single place.\n\n# What It's Good For\n\nAutoKitteh acts as the **glue** to connect apps for:  \n\ud83d\udd39 **DevOps** \u2013 Automate CI/CD, alerting, deployments, and monitoring.  \n\ud83d\udd39 **AI-Assisted Workflows** \u2013 Chain AI models with APIs, preprocess data, and automate interactions.  \n\ud83d\udd39 **Internal Automations** \u2013 Automate org workflows like onboarding, approval processes, and reporting.  \n\ud83d\udd39 **Personal Workflows** \u2013 Create event-driven automations without worrying about infrastructure.\n\n**Comparison**\n\nFor automation, there are:  \n\ud83d\udd39 **No-Code Tools** \u2013 Zapier, Make, Workato etc.\u2013 great for non-devs, but limited for complex workflows.  \n\ud83d\udd39 **Low-Code Platforms** \u2013 n8n, Pipedream etc.\u2013 allow custom logic but aren't optimized for durability and not all are self hosted.  \n\ud83d\udd39 **Durable Automation Platforms** \u2013 Temporal, Restate, DBOS \u2013 AutoKitteh provides similar reliability but with **higher-level Python abstractions** instead of requiring workflow-specific frameworks.\n\n**Target Audience**\n\n\ud83d\udc0d **Any Python developer** who wants to connect APIs reliably and efficiently.  \n\ud83d\ude80 **AI builders** integrating LLMs and external services.  \n\ud83d\udee0\ufe0f **Developers who need durable workflows** without managing servers, infrastructure, or security.  \n\ud83d\udca1 **Builders who can write Python** but don\u2019t want to deal with ops overhead.</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iyzp2m/workflow_automation_for_python_developers/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iyzp2m/workflow_automation_for_python_developers/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "80",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iso1bl/micropie_0993_released/"
            },
            "content": "<p>MicroPie 0.9.9.3 Released</p><p>This week I released version 0.9.9.3 of my (optionally) single file ASGI \"ultra-micro\" framework, [MicroPie](https://patx.github.io/micropie). \n\nThis release introduces many new things since the last time I announced a release on here about 4 weeks ago... We now have the ability to implement custom session backends like `aioredis` and `motor` using the `SessionBackend` class. We also have introduced middleware so you can hook into incoming requests. Check out the [source code, a ton of examples and documentation on GitHub](https://github.com/patx/micropie).\n\n**MicroPie's Key Features**\n- \ud83d\udd04 Routing: Automatic mapping of URLs to functions with support for dynamic and query parameters.\n- \ud83d\udd12 Sessions: Simple, plugable, session management using cookies.\n- \ud83c\udfa8 Templates: Jinja2, if installed, for rendering dynamic HTML pages.\n- \u2699\ufe0f Middleware: Support for custom request middleware enabling functions like rate limiting, authentication, logging, and more.\n- \u2728 ASGI-Powered: Built w/ asynchronous support for modern web servers like Uvicorn and Daphne, enabling high concurrency.\n- \ud83d\udee0\ufe0f Lightweight Design: Minimal dependencies for faster development and deployment.\n- \u26a1 Blazing Fast: Checkout the benchmarks.\n\n**This is an alpha release. Please file [issues/requests](https://github.com/patx/micropie/issues) as you encounter them! Thank you!**\n</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iso1bl/micropie_0993_released/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iso1bl/micropie_0993_released/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "81",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iia3x7/not_just_another_gof_design_patterns_resource/"
            },
            "content": "<p>Not just another GoF design patterns resource: Functional, Reactive, Architectural, Concurrency, ...</p><p>Looking to enhance your Python skills with real-world software design knowledge? Check out the newly published \u201cPython Design Patterns Guide\u201d at Software Patterns Lexicon. It\u2019s not just another OOP GoF design patterns resource\u2014this comprehensive, Python-specific, open-source guide covers everything from functional and reactive patterns to concurrency and architectural concerns.\n\n\u2022 Website: [https://softwarepatternslexicon.com/patterns-python/](https://softwarepatternslexicon.com/patterns-python/)\n\n\u2022 Open Source on GitHub: All the content is openly available, so you can dive in, learn, and even contribute!\n\nEach chapter explores a vital aspect of design patterns, from their history and evolution to practical implementations and best practices in Python. You\u2019ll find interactive quizzes (10 questions each) at the end of every page to test your understanding, making it easy to gauge your progress.</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iia3x7/not_just_another_gof_design_patterns_resource/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iia3x7/not_just_another_gof_design_patterns_resource/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "82",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iy4h5k/cracking_the_python_monorepo_build_pipelines_with/"
            },
            "content": "<p>Cracking the Python Monorepo: build pipelines with uv and Dagger</p><p>Hi r/Python!\n\n# What My Project Does\nHere is my [approach](https://gafni.dev/blog/cracking-the-python-monorepo/) to boilerplate-free and very efficient [Dagger](https://dagger.io/) pipelines for Python monorepos managed by [uv workspaces](https://docs.astral.sh/uv/concepts/projects/workspaces/).\nTLDR: the `uv.lock` file contains the graph of cross-project dependencies inside the monorepo. It can be used to programmatically define docker builds with some very nice properties. Dagger allows writing such build pipelines in Python.\nIt took a while for me to crystallize this idea, although now it seems quite obvious. Sharing it here so others can try it out too!\n\n## Teaser\nIn this post, I am going to share an approach to building Python monorepos that solves these issues in a very elegant way. The benefits of this approach are:\n- **it works with any `uv` project** (even yours!)\n- **it needs little to zero maintenance and boilerplate**\n- **it provides end-to-end pipeline caching** --- including steps downstream to building the image (like running linters and tests), which is quite rare\n- **it's easy to run locally and in CI**\n\n## Example workflow\nThis short example shows how the built Dagger function can automatically discover and build any uv workspace member in the monorepo with dependencies on other members without additional configuration:\n```shell\nuv init --package --lib weird-location/nested/lib-three\nuv add --package lib-three lib-one lib-two\ndagger call build-project --root-dir . --project lib-three\n```\nThe programmatically generated build is also cached efficiently.\n\n# Target Audience\nEngineers working on large monorepos with complicated cross-project dependencies and CI/CD.\n\n# Comparison\nAlternatives are not known to me (it's hard to do a comparison as the problem space is not very well defined).\n\n# Links\n- [the blog post](https://gafni.dev/blog/cracking-the-python-monorepo/).\n- [source code](https://github.com/danielgafni/website/tree/master/www/content/blog/cracking-the-python-monorepo/uv-dagger-dream).</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iy4h5k/cracking_the_python_monorepo_build_pipelines_with/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iy4h5k/cracking_the_python_monorepo_build_pipelines_with/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "83",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iura9d/redpoint_python_library_for_converting_climbing/"
            },
            "content": "<p>\ud83d\udd34 redpoint - Python library for converting climbing grades between different grading systems</p><p>GitHub: [https://github.com/ciszko/redpoint](https://github.com/ciszko/redpoint)\n\n**What my project does**\n\nIn rock climbing, various climbing styles (sport, boulder, ice) have their own grading systems. What's more, some systems were initially developed in confined geographical areas, climbing areas, countries or continents. `\ud83d\udd34 redpoint`\u00a0is a Python library that simplifies climbing grade conversions. It supports a wide range of climbing grade systems (sport, bouldering, and other) from [thecrag.com](http://thecrag.com), allowing users to easily convert between systems (e.g., Yosemitee Decimal System to French), compare the difficulty of grades, and even generate ranges of equivalent grades.\n\nThe features include:\n\n* Converting the grades between the systems\n* Comparing the difficulty of grades (even between the systems)\n* Converting a grade into a range of grades from the different system\n* Iterating over grades from specific systems\n* Finding X harder or lower grade\n\nI've always wanted to combine programming and climbing. I didn't find any Python library that would cover that many grading systems so I decided to give it a go. Besides that, I had the opportunity to upload my library to pypi which was a new experience.\n\n**Target Audience**  \n(mostly rock climbers)  \nI find it hard to to compare the grades in my head, especially when I've never been to a specific climbing area that uses a different system. Thus I think that people that are having similar issues could use this project. It could be a learning mechanism for memorizing the new systems (it was for me when I was testing it :P)</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iura9d/redpoint_python_library_for_converting_climbing/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iura9d/redpoint_python_library_for_converting_climbing/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "84",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iuy6kg/hello_i_made_a_small_webapp_with_streamlit/"
            },
            "content": "<p>Hello, I made a small webapp with Streamlit, FastAPI and docker to convert my images to PDFs</p><p>Hi! \n\nI started my self-hosted journey a couple of days ago, and this is my first webapp in a docker container.   \nIt converts images to PDFs and merge PDFs together based on existing libraries. \n\nIt taught me how to use FastApi with streamlit, and how to make them speak to each other with docker. I hope it can help you too! ;)\n\n[https://github.com/LittleYellowPanda/MakeItPrivate.git](https://github.com/LittleYellowPanda/MakeItPrivate.git)\n\nIf you have any questions, or advice, feel free to comment! \n\n</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iuy6kg/hello_i_made_a_small_webapp_with_streamlit/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iuy6kg/hello_i_made_a_small_webapp_with_streamlit/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "85",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ii2tqh/typedffmpeg_2x_released_with_new_command/"
            },
            "content": "<p>typed-ffmpeg 2.X released with New Command Validation Feature</p><p>**What My Project Does**\n\n**typed-ffmpeg** offers a modern, Pythonic interface to FFmpeg, providing extensive support for complex filters with detailed typing and documentation. Inspired by\u00a0`ffmpeg-python`, this package enhances functionality by addressing common limitations, such as lack of IDE integration and comprehensive typing, while also introducing new features like JSON serialization of filter graphs and automatic FFmpeg validation.\n\n[https://github.com/livingbio/typed-ffmpeg](https://github.com/livingbio/typed-ffmpeg)\n\n**Target Audience**: \n\nThis project is aimed at developers working on multimedia applications, educational content, or data analysis involving video and audio processing. It's suitable for both production and experimental projects, offering a balance between ease of use and robust functionality.\n\n**Comparison:**\n\nVer2.0 announce some new features:\u00a0include **Command Validation and Auto-Correction**. This enhancement ensures that your FFmpeg commands are both syntactically correct and optimized for execution, reducing the likelihood of errors and streamlining your media processing workflows.\n\nmore details: [https://livingbio.github.io/typed-ffmpeg/usage/execute/#validate-auto-fix-with-typed-ffmpeg](https://livingbio.github.io/typed-ffmpeg/usage/execute/#validate-auto-fix-with-typed-ffmpeg)</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ii2tqh/typedffmpeg_2x_released_with_new_command/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ii2tqh/typedffmpeg_2x_released_with_new_command/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "86",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ifqz4j/pedroreportsan_open_source_llm_powered_automated/"
            },
            "content": "<p>PedroReports-An Open Source LLM Powered Automated Data Analysis Report Generator Tool</p><p>Hey devs! Sharing my first project - an AI-powered PDF Report Generator! \ud83d\udc0d\ud83d\udcca\n\n## GitHub:\nPlease checkout GitHub Repo for Tutorial Video\n https://github.com/bobinsingh/PedroReports-LLM-Powered-Report-Tool\n\nI recently switched my career from life sciences to coding, and I wanted to create something useful after learning. So I built a tool that generates professional data analysis PDF reports from any tabular dataset. You just need to input what you want to analyze, and it does the job for you. Thought you might find it interesting!\n\n# What My Project Does:\n\n- Takes your dataset and analysis requirements as input in the form of questions\n- Uses Gemini API to generate graphs and relevant stats to answer your questions\n- Generates a professional PDF with proper formatting\n- Handles TOC, styling, and page numbers automatically\n\n# Target Audience:\n- Data Analysts, BI reporters \n- Data Science beginners who want quick data insights \n- Researchers who are not friendly with coding \n\n# Comparison \n- There are a lot of BI tools out there but not sure if they generate PDF reports or not.\n\n## Tech Stack:\n\n- Python + ReportLab for PDF generation\n- React + Vite for frontend and development server \n- LangChain + Gemini API for analysis\n- Pandas/Numpy/Matplotlib for data processing\n\nThe workflow is simple: feed it your data, and it handles everything from visualization to creating a fully formatted report with AI-generated descriptions. No more manual report writing! \ud83c\udf89\n\nCheck it out on Github! Happy to answer any questions.</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ifqz4j/pedroreportsan_open_source_llm_powered_automated/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ifqz4j/pedroreportsan_open_source_llm_powered_automated/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "87",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ipc9p1/building_deepseek_r1_from_scratch/"
            },
            "content": "<p>Building DeepSeek R1 from Scratch</p><p># What My Project Does\n\nI created a complete learning project in a **Jupyter Notebook** to build a DeepSeek R1 lookalike from scratch. It covers everything from preprocessing the training dataset to generating text with the trained model.\n\n# Target audience\n\nThis project is for students and researchers who want to understand how DeepSeek R1 is implemented. **While it has some errors** \ud83d\ude28, it can still be used as a guide to build a tiny version of DeepSeek R1.\n\n# Comparison\n\nThis project is a simpler version of DeepSeek R1, made for learning. It\u2019s not perfect, but it helps understand how DeepSeek R1 works and lets you build a small version yourself.\n\n# GitHub\n\nCode, documentation, and example can all be found on GitHub:\n\n[https://github.com/FareedKhan-dev/train-deepseek-r1](https://github.com/FareedKhan-dev/train-deepseek-r1)</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ipc9p1/building_deepseek_r1_from_scratch/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ipc9p1/building_deepseek_r1_from_scratch/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "88",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1im12r8/i_made_versioneer_work_with_hatchling_and_pdm/"
            },
            "content": "<p>I made Versioneer work with Hatchling and pdm build backends</p><p>[version-pioneer](https://github.com/kiyoon/version-pioneer) is a fork of Versioneer that supports Hatchling and pdm build backends.\n\nThe reason I hesitated for so long to switch from setuptools to hatchling etc. was Versioneer. I believe versioning system should be independent from the backend you use so you can easily migrate. Not only that you have to learn a new system, but also they don't work the same way. For example, I noticed other VCS versioning systems do not support dynamic version resolution in editable installs (`pip install -e .`), which means while developing you will often get incorrect version.\n\n### What My Project Does:\n\n- **Highly customisable**: It's an easy-to-read script. [Literally a simple Python script](https://github.com/kiyoon/version-pioneer/blob/master/src/version_pioneer/versionscript.py) in which you can customise the version format or anything you need.\n- \ud83d\udc0d Runs with Python 3.8+\n- \u274c\ud83d\udce6 No dependencies like package, config file etc. It runs with one Python file. \n- \u2b55 Works with any build backend with hooks. (Supports setuptools, hatchling, pdm)\n- \ud83e\udd80 Works with any language, not just Python.\n    - Version format `\"digits\"` generates digits-only version string which is useful for multi-language projects, Chrome Extension, etc. because their versioning standard is different.\n    - CLI makes it easy to compute the version without vendoring anything in the project.\n- \ud83e\ude79 Can resolve version even when the git info is missing.\n    - Downloaded from GitHub Releases? Read from the directory name.\n        - The `parentdir_prefix` is automatically resolved from `pyproject.toml`'s source URL etc.\n    - sdist built without writing a resolved versionfile?\n        - Read from PKG-INFO. \n- \ud83d\udd22 New version formats:\n    - `\"pep440-master\"`: shows the distance from the tag to master/main, and the master to the current branch. (e.g. 1.2.3&#8203;**+4.gxxxxxxx**&#8203;_.5.gxxxxxxx_ )\n    - `\"digits\"`: the distance and dirty information compiled to the last digit. (e.g. 1.2.3&#8203;**.4**)\n- </> API provided for complete non-vendored mode support.\n    - With Versioneer you still had to install a `_version.py` script in your project, but Version-Pioneer is able to be installed as a package.\n- \ud83d\udcbb CLI tool to get version string, execute the `_version.py` versionscript, and test your setup.\n\n### Target Audience:\n\nDevelopers who ...\n\n- want to systematically manage version string.\n- are looking for a robust, easy-to-use solution.\n- want it to be fully customisable.\n\n### Comparison:\n\n[Versioneer](https://github.com/python-versioneer/python-versioneer) finds the closest git tag like `v1.2.3` and generates a version string like `1.2.3+4.gxxxxxxx.dirty`.\n\n- `1.2.3` is the closest git tag.\n- `+4` is the number of commits since the tag.\n- `gxxxxxxx` is the git commit hash (without the leading `g`).\n- `.dirty` is appended if the working directory is dirty (i.e. has uncommitted changes).\n\n[setuptools-scm](https://github.com/pypa/setuptools-scm) is a similar tool, but with some differences:\n\n- How the version string is rendered: `1.2.3+4.gxxxxxxx.dirty` vs `1.2.4.dev4+gxxxxxxx`\n    - No `.dirty` in setuptools-scm.\n    - Infer the next version number (i.e. 1.2.4 instead of 1.2.3).\n- The `_version.py` file is always a constant in setuptools-scm.\n    - Versioneer can dynamically generate the version string at runtime, so it's always up-to-date. Useful for development (pip install -e .).\n    - Setuptools-scm won't ever change the version string after installation. You need to reinstall to update the version string.\n\nI have used versioneer for years, and I like the format and dynamic resolution of versions for development. However,\n\n1. It doesn't support any build backends other than `setuptools` (like `pdm`, `hatchling`, `poetry`, `maturin`, `scikit-build`, etc.)\n2. It doesn't support projects that are not Python (like Rust, Chrome Extension, etc.).\n\nEvery time I had to figure out how to integrate a new VCS versioning plugin but they all work differently and produce different version strings. GitHub Actions and other tools may not work with all different version format. Different language usually expects different format, and it's especially hard to make it compatible for mixed language projects.\n\nThe original versioneer is 99% boilerplate code to make it work with all legacy setuptools configurations, trying to \"generate\" code depending on the configuration, etc.. But the core functionality is simple: just get version from git tag and format it. I had to leverage this logic to integrate Versioneer in every project I had.</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1im12r8/i_made_versioneer_work_with_hatchling_and_pdm/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1im12r8/i_made_versioneer_work_with_hatchling_and_pdm/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "89",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1izqk1x/spider_distributed_web_crawler_built_with_async/"
            },
            "content": "<p>Spider: Distributed Web Crawler Built with Async Python</p><p>Hey everyone,\n\nI'm a junior dev diving into the world of web scraping and distributed systems, and I've built a modern web crawler that I wanted to share. Here\u2019s a quick rundown:\n\n* **What It Does:** It\u2019s a distributed web crawler that fetches, processes, and saves web data using asynchronous Python (aiohttp), Celery for managing tasks, and PostgreSQL for storage. Plus, it comes with a flexible plugin system so you can easily add custom features.\n* **Target Audience:** This isn\u2019t just a toy project\u2014it's designed and meant to be used for real-world use. If you're a developer, data engineer, or just curious about scalable web scraping solutions, this might be right up your alley. It\u2019s also a great learning resource if you\u2019re getting started with async programming and distributed architectures.\n* **How It Differs:** Unlike many basic crawlers that run in a single thread or block on I/O, my crawler uses asynchronous calls and distributed task management to handle lots of URLs efficiently. Its modular design and plugin architecture make it super flexible compared to more rigid, traditional alternatives.\n\nI\u2019d love to get your thoughts, feedback, or even tips on improving it further! Check out the repo here: [https://github.com/roshanlam/Spider](https://github.com/roshanlam/Spider)</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1izqk1x/spider_distributed_web_crawler_built_with_async/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1izqk1x/spider_distributed_web_crawler_built_with_async/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "90",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ixblib/i_just_got_rickrolled_by_codeium_in_vs_code/"
            },
            "content": "<p>I just got RickRolled by Codeium in VS Code</p><p>https://i.ibb.co/kfw0RnN/Untitled.png\n\nNow, since I was writing (very awful) python code, I thought I'd drop this here. I, like most, use AI code completion as needed but generally have it hotkeyed to something so it doesn't ghost insert the first hallucination directly into my butt mid-function or something. I'm really trying to get behind Textual for my (again, very awful) personal TUI mpv replacement/music stream/searcher that doesn't break every two weeks like yewtube does (wonderful python app though, love it). Anyway, I added a stupid ability to fetch thumbnails automatically and display them using `rich-pixels` as a Renderable and I was lazy and thought I'd see what Codeium suggested I use as a fallback generic thumbnail for local playlists I open.. First auto-complete suggest and I Tab accepted it and figured it was an ID for an example from the YouTube docs or something. I shit you not, this was its first, immediate, not-even-thinking-slowly-because-your-code-sucks auto suggestion:\n\nhttps://img.youtube.com/vi/dQw4w9WgXcQ/maxresdefault.jpg</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ixblib/i_just_got_rickrolled_by_codeium_in_vs_code/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ixblib/i_just_got_rickrolled_by_codeium_in_vs_code/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "91",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1is6amk/greenlets_in_a_post_gil_world/"
            },
            "content": "<p>Greenlets in a post GIL world</p><p>I've been following the release of the optional disable GIL feature of Python 3.13 and wonder if it'll make any sense to use plain Python threads for CPU bound tasks? \n\n\nI have a flask app on gunicorn with 1 CPU intensive task that sometimes squeezes out I/O traffic from the application. I used a greenlet for the CPU task but even so, adding yields all over the place complicated the code and still created holes where the greenlet simply didn't let go of the silicon. \n\n\nI finally just launched a multiprocess for the task and while everyone is happy I had to make some architectural changes in the application to make data churned out in the CPU intensive process available to the base flask app. \n\nSo if I can instead turn off yet GIL and launch this CPU task as a thread will it work better than a greenlet that might not yield under certain load patterns?</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1is6amk/greenlets_in_a_post_gil_world/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1is6amk/greenlets_in_a_post_gil_world/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "92",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ilhnfm/two_fast_auth_a_fastapi_extension_to_implement_2fa/"
            },
            "content": "<p>Two Fast Auth - A FastAPI extension to implement 2FA</p><p>Hi everyone,\n\nI've published **Two Fast Auth**:\n\n**Documentation**: [rennf93.github.io/two-fast-auth/](https://rennf93.github.io/two-fast-auth/)\n\n**GitHub repo**: [github.com/rennf93/two-fast-auth](https://github.com/rennf93/two-fast-auth)\n\n**What is it?**\n\nTwo Fast Auth is a FastAPI middleware that provides seamless two-factor authentication implementation with:\n\n- QR code generation for authenticator apps\n- Time-based one-time password (TOTP) verification\n- Secure recovery code management\n- Optional secret encryption\n- Middleware integration for route protection\n- Production-ready configuration defaults\n\nMIT licensed and designed specifically for FastAPI applications.\n\n**Comparison to alternatives**:\n- `fastapi-jwt-auth`: Focuses on JWT authentication without native 2FA\n- `python-otp`: Provides OTP generation but no framework integration\n- `authlib`: General-purpose auth library without FastAPI-specific middleware\n\n**Key differentiators**:\n- Native FastAPI middleware implementation\n- Built-in QR code generation endpoint\n- Recovery code lifecycle management\n- Fernet encryption for secret storage\n- Zero-configuration defaults for quick setup\n- Active maintenance with production use cases\n\n**Target Audience**:\nFastAPI developers needing:\n- Quick 2FA implementation without vendor lock-in\n- Compliance with security standards requiring MFA\n- Recovery code workflows for end-users\n- Encrypted secret storage capabilities\n- QR code-based authenticator app setup\n\n**Feedback wanted :)**\n\nThanks!</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ilhnfm/two_fast_auth_a_fastapi_extension_to_implement_2fa/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ilhnfm/two_fast_auth_a_fastapi_extension_to_implement_2fa/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "93",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ikizbe/a_lightweight_camera_sdk_for_windows_macos_and/"
            },
            "content": "<p>A Lightweight Camera SDK for Windows, macOS, and Linux</p><p>If you\u2019re looking for a lightweight alternative to OpenCV for camera access on Windows, Linux, and macOS, I\u2019ve created a minimal SDK called [lite-camera](https://pypi.org/project/lite-camera/) .\n\n**Installation**\n\n    pip install lite-camera\n\n**Quick Usage**\n\n    import litecam\n    \n    camera = litecam.PyCamera()\n    \n    if camera.open(0):\n    \n        window = litecam.PyWindow(\n            camera.getWidth(), camera.getHeight(), \"Camera Stream\")\n    \n        while window.waitKey('q'):\n            frame = camera.captureFrame()\n            if frame is not None:\n                width = frame[0]\n                height = frame[1]\n                size = frame[2]\n                data = frame[3]\n                window.showFrame(width, height, data)\n    \n        camera.release()</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ikizbe/a_lightweight_camera_sdk_for_windows_macos_and/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ikizbe/a_lightweight_camera_sdk_for_windows_macos_and/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "94",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iq5jlz/inviting_contributions_to_a_open_source_django/"
            },
            "content": "<p>Inviting contributions to a open source Django chat web app !</p><p>Hey everyone!\n\nI\u2019ve built a basic Django chat app using Django Channels & WebSockets, and I\u2019d love to open it up for community contributions! The project is still in its early stages, and I believe it would be more exciting to build it together rather than alone.\n\nI've opened multiple issues (friend requests, message indicators, PostgreSQL integration, etc.), so feel free to pick one, suggest improvements, or even add new features! It\u2019s a great way to gain experience, build your portfolio, and collaborate with others.\n\nRepo Link :\u00a0[https://github.com/frzn23/zeenchat](https://github.com/frzn23/zeenchat)\n\nWould love to hear your thoughts and ideas!</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iq5jlz/inviting_contributions_to_a_open_source_django/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iq5jlz/inviting_contributions_to_a_open_source_django/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "95",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ip73nx/pyatomix_a_tiny_atomics_library_for_python_313t/"
            },
            "content": "<p>pyatomix, a tiny atomics library for Python 3.13t</p><p>* What My Project Does\n\nit provides an AtomicInt and AtomicFlag class from std::atomic<int64_t> and std::atomic_flag, and exposes the same API.  AtomicInt also overloads math operators so += for instance is an atomic increment.\n\nhttps://github.com/0xDEADFED5/pyatomix\n\n* Target Audience\n\nAnyone who wants an easy to use atomic int or atomic flag.  I don't see why it couldn't be used in production.\n\n* Comparison\n\nI was having trouble a while back finding a simple atomics library for Python 3.13t that either had wheels for Windows, or would build easily without fuss on Windows, so I made one. Wheels are available for the main platforms, but it builds easily on Windows and Linux. (C++ 20 required to build)</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ip73nx/pyatomix_a_tiny_atomics_library_for_python_313t/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1ip73nx/pyatomix_a_tiny_atomics_library_for_python_313t/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "96",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iu4nzo/currency_classes_for_python/"
            },
            "content": "<p>Currency classes for Python</p><p># [Monepy](https://github.com/vsbits/monepy)\n\nA python package that implements currency classes to work with monetary values.\n\n# Target audience\n\nI created it mostly for some data analysis tasks I usually do, and also as way to learn about project structure, documentation, github actions and how to publish packages.\n\nI wouldn't know if it's production ready.\n\n# Comparison\n\nAfter starting it I found about [py-moneyed](https://github.com/py-moneyed/py-moneyed). They are quite similar, but I wanted something that looks \"cleaner\" when using it.\n\nAny feedback will be appreciated.</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iu4nzo/currency_classes_for_python/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iu4nzo/currency_classes_for_python/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "97",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iiya1h/using_type_hintsannotation_to_create_functional/"
            },
            "content": "<p>Using type hints/annotation to create functional code: Bad or Good practice?</p><p>I recently implemented a feature in [**datatrees**](https://pypi.org/project/datatrees/) where the type annotation is used to optionally provide the class used by the datatrees.Node default value.\n\n    class A:\n        a: int = 1\n    \n    # Pre v0.1.9, Nodes needed to be defaulted explicitly.\n    class B:\n        a: Node[A] = Node(A)\n    \n    # With v0.1.9, the default will be provided implicitly. Class C an B are identical.\n    class C:\n        a: Node[A]\n\nI also made it so that Node instances missing the class parameter will be filled in at the datatree initialization phase. i.e.\n\n    class D:\n        a: Node[A] = Node('a') # Shorthand for Node(A, 'a')\n    \n    class E:\n        a: Node[A] = dtfield(init=False) # Shorthand for dtfield(Node(A), init=False)\n\nI felt that this was a big win by eliminating repetitive code like `a: Node[A] = Node(A)` which eliminates the chances of doing something accidently like `a: Node[A] = Node(Z)` which more than likely is not what you want.\n\nI've never seen any other library do this (use type annotations to provide runtime context) so I'm not sure if I'm breaking something I shouldn't be breaking so  any thoughts on how badly I've transgressed the Python norms are welcome.\n\nThen again, [**datatrees**](https://pypi.org/project/datatrees/) is itself pushing boundaries for some people so maybe we'll just leave this in the grey area.</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iiya1h/using_type_hintsannotation_to_create_functional/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.357638Z",
            "url": "https://www.reddit.com/r/Python/comments/1iiya1h/using_type_hintsannotation_to_create_functional/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "98",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1iic6m0/what_do_you_like_more/"
            },
            "content": "<p>What do you like more</p><p>Simple question regarding style, I don\u2019t believe there is a right answer just curious because I had a disagreement with a colleague at work about this.\n\n1. flag = False if var in [\u201cstr1\u201d, \u201cstr2\u201d] else True\n2. flag = var not in [\u201cstr1\u201d, \u201cstr2\u201d]</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1iic6m0/what_do_you_like_more/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.358547Z",
            "url": "https://www.reddit.com/r/Python/comments/1iic6m0/what_do_you_like_more/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        },
        {
            "id": "99",
            "account": {
                "username": "RedditUser",
                "acct": "RedditUser@reddit.com",
                "display_name": "Reddit Post",
                "avatar": "https://www.redditstatic.com/avatars/default.png",
                "url": "https://www.reddit.com/r/Python/comments/1ih6bo6/introducing_elixirdb_simplified_sqlalchemy_engine/"
            },
            "content": "<p>Introducing ElixirDB - Simplified SQLAlchemy Engine management - with extras.</p><p>Hello,\n\nI'm building libraries (the previous one was similar to this) to get criticism to improve my code and logic because even as a professional developer, I've never had a senior engineer/dev. I took in some feedback from the previous library to make something potentially useful this time.\n\nThis is a pre-release, so there are some things I'm ironing out. Let me know what you guys think. Always looking for criticism.\n\nGithub: https://github.com/hotnsoursoup/elixirdb\n\nPypi: https://pypi.org/project/elixirdb/\n\nWhat My Project Does:\nElixirDB simplifies interaction with SQLAlchemy, providing streamlined database operations, enhanced configuration management, and improved developer experience.\n\nTarget Audience:  \nAnyone that wants to stand up a quick database connection or may want the flexibility of switching engines from a central class. Perhaps you don't like the way sqlalchemy binds engines.\n\nComparison:\nNot sure, I couldn't really find anything out there. I did try googling quite a bit and even asked 3 different AI models to find me one, but it didn't come up with anything. I'd love for any references.\n\n# Key Features (Reduced, more on github/pypi)\n\n* **Automatic loading:**\u00a0Define an **elixir**.yaml file in your project, and it will be automatically loaded into the ElixirDB instance.\n* **Pydantic Integration:**\u00a0Define and validate database configurations using Pydantic models\n* **Multi-Engine Support:**\u00a0Seamlessly manage multiple database engines through a central class object.\n* **Multi-dialect Support:**\u00a0Support for MySQL/MariaDB, postgresql, Oracle, and MSSQL.\n* **Engine Types:**\u00a0Supports `direct`, `session` and `scoped_session`\n* **Handler Framework:**\u00a0A flexible handler framework empowers customized processing of parameters, result_objects, and central error control - mirroring middleware functionality.\n* **Stored Procedure Support:**\u00a0Execute stored procedures with ease, with automatically generated statements based on dialect.\n\nBasic Usage\n```console\nfrom elixirdb import ElixirDB\n\n\ntry:\n    connection = ElixirDB(engine_key=\"mysql\")\nexcept FileNotFoundError:\n    print(\"No elixir.yaml file found.\")\n```\n\nSample yaml configuration for EngineManager\n\n```yaml\napp:\n    defaults: # All engines adopt these as a base.\n        engine_options:\n            echo: False\n            pool_size: 20\n            max_overflow: 10\n            pool_recycle: 3600\nengines:\n    dbkey1:\n        dialect: mysql\n        url: mysql+pymysql://user:password@localhost:3306/db1\n        default: true # Default engine if engine_key is not provided.\n        execution_options:\n            autocommit: True\n            isolation_level: READ_COMMITTED\n            preserve_rowcount: True\n    loggingdb:\n        dialect: postgres\n        url_params:\n            drivername: psycopg2\n            host: localhost\n            port: 5432\n            user: postgres\n            password: password\n            query:\n                schema: public\n        engine_options:\n            echo: True\n            pool_timeout: 30\n            hide_parameters: True\n    customerdb:\n        dialect: oracle\n        url: oracle+cx_oracle://user:password@localhost:1521/orcl\n```</p><p>Original post: <a href=\"https://www.reddit.com/r/Python/comments/1ih6bo6/introducing_elixirdb_simplified_sqlalchemy_engine/\" target=\"_blank\">View on Reddit</a></p>",
            "created_at": "2025-03-02T01:11:13.358547Z",
            "url": "https://www.reddit.com/r/Python/comments/1ih6bo6/introducing_elixirdb_simplified_sqlalchemy_engine/",
            "visibility": "public",
            "media_attachments": [],
            "tags": []
        }
    ]
}